<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[多线程-强软弱虚]]></title>
    <url>%2F2021%2F01%2F11%2F%E5%A4%9A%E7%BA%BF%E7%A8%8B-%E5%BC%BA%E8%BD%AF%E8%8B%A5%E8%99%9A%2F</url>
    <content type="text"><![CDATA[前言Java中有强软弱虚四种引用。 强引用(Strong Reference)正常用new声明的对象都是强引用。 强引用不会被垃圾回收。 软引用(Soft Reference) 使用方法： 1SoftReference&lt;Object&gt; m = new SoftReference&lt;&gt;(obj); 特性：只有系统内存不够用时，被软引用指向的对象才会被回收。 使用场景：memory cache 弱引用(Weak Reference) 使用方法： 1WeakReference&lt;Object&gt; m = new WeakReference&lt;&gt;(obj); 特性：如果只有弱引用，只要遭遇垃圾回收，就会被回收。 使用场景： WeakHashMap ThreadLocal： ThreadLocal中的ThreadLocalMap的key就WeakReference 由于ThreadLocalMap是Thread类的成员，因此其生命周期是和Thread相同的，该map中的key是ThreadLocal实例，如果某个ThreadLocal实例用完不用了，但由于map中还有对该实例的引用，因此，GC不会回收该对象，就会导致内存泄露，而使用弱引用之后，当外部的强引用消失之后，只剩弱引用，就会被回收了。 ThreadLocalMap中的value还是强引用，因此如果ThreadLocal不用了，还是要调用remove()方法。 虚引用(Phantom Reference) 使用方法： 1PhantomReference&lt;Obj&gt; m = new PhantomReference&lt;&gt;(obj, QUEUE); 特性： 如果只有虚引用，只要遭遇垃圾回收，就会被回收，回收后，QUEUE中会放入此对象 检查QUEUE就能知道虚引用指向的对象是否被回收 应用：用于管理堆外内存（Direct Memory）]]></content>
      <categories>
        <category>多线程</category>
      </categories>
      <tags>
        <tag>多线程</tag>
        <tag>强软若虚</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[多线程-ThreadLocal]]></title>
    <url>%2F2021%2F01%2F10%2F%E5%A4%9A%E7%BA%BF%E7%A8%8B-ThreadLocal%2F</url>
    <content type="text"><![CDATA[前言ThreadLocal的特性和底层实现。 用法12345678/* 声明ThreadLocal */ThreadLocal&lt;Obj&gt; tl = new ThreadLocal&lt;&gt;();/* 设置ThreadLocal */tl.set(obj);/* 读取ThreadLocal */Obj obj2 = tl.get();/* 使用完后，需要手动remove，否则会导致内存泄露 */tl.remove(); 特性不同线程对同一个ThreadLocal对象的操作是相互独立和隔离的，不会相互影响。 底层实现我们看一下 ThreadLocal 类中最常用的几个方法： Set12345678public void set(T value) &#123; Thread t = Thread.currentThread(); ThreadLocalMap map = getMap(t); if (map != null) map.set(this, value); else createMap(t, value);&#125; Get12345678910111213public T get() &#123; Thread t = Thread.currentThread(); ThreadLocalMap map = getMap(t); if (map != null) &#123; ThreadLocalMap.Entry e = map.getEntry(this); if (e != null) &#123; @SuppressWarnings("unchecked") T result = (T)e.value; return result; &#125; &#125; return setInitialValue();&#125; Remove12345public void remove() &#123; ThreadLocalMap m = getMap(Thread.currentThread()); if (m != null) m.remove(this);&#125; 上面三个函数一开头都用到了getMap()方法，我们来看一下： 123ThreadLocalMap getMap(Thread t) &#123; return t.threadLocals;&#125; 非常简单，直接返回线程Thread对象中的threadLocals变量，我们来看一下Thread类： 12345public class Thread implements Runnable &#123; ... ThreadLocal.ThreadLocalMap threadLocals = null; ...&#125; 可以看到Thread类中确实有 ThreadLocalMap 实例，也就是说，每个线程中都有这么一张Map，再结合 Set 和 Get 方法，可以看出，这个Map中，各个条目以ThreadLocal实例为key，值为value来存储。 同一个ThreadLocal实例对不同Thread隔离，就是这么实现的。 此外值得注意的是，ThreadLocalMap中的key是弱引用，之所以是弱引用是因为：ThreadLocalMap是Thread类的成员，因此其生命周期是和Thread相同的，如果该map中的key是ThreadLocal实例，如果某个ThreadLocal实例用完不用了，但由于map中还有对该实例的引用，因此，GC不会回收该对象，就会导致内存泄露，而使用弱引用之后，当外部的强引用消失之后，只剩弱引用，就会被回收了。 123456789101112131415static class ThreadLocalMap &#123; static class Entry extends WeakReference&lt;ThreadLocal&lt;?&gt;&gt; &#123; Object value; Entry(ThreadLocal&lt;?&gt; k, Object v) &#123; super(k); value = v; &#125; &#125; private static final int INITIAL_CAPACITY = 16; private Entry[] table; private int size = 0; private int threshold; // Default to 0 ...&#125; ThreadLocalMap中的value还是强引用，因此如果ThreadLocal不用了，还是要调用remove()方法。 使用场景比如连接池应用，使用ThreadLocal可以保存连接。]]></content>
      <categories>
        <category>多线程</category>
      </categories>
      <tags>
        <tag>多线程</tag>
        <tag>ThreadLocal</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[多线程-AQS源码分析]]></title>
    <url>%2F2021%2F01%2F08%2F%E5%A4%9A%E7%BA%BF%E7%A8%8B-AQS2%2F</url>
    <content type="text"><![CDATA[前言之前我们已经对JUC中的各种同步器有所了解，并且看到了ReentrantLock、ReentrantReadWriteLock、CountDownLatch、Semaphore这些同步器内部都是通过AQS（Abstract Queued Synchronizer）来实现的。 我们就来看看AQS的源码。 AQS概览在分析AQS的源码之前，我们先从整体脉络上来理解AQS的设计思路。 AQS功能ReentrantLock、ReentrantReadWriteLock、CountDownLatch、Semaphore这些同步器都是基于AQS实现的，它们的功能都是实现多线程间的协调同步，因此，AQS便是将多线程同步中的共性逻辑抽象了出来。 首先，由JMM我们知道，多线程之间同步肯定少不了通过共享变量来实现信息在多个线程之间的传递； 其次，多线程编程中往往涉及到等待，比如等待其他线程的结果、等待锁等等（最终归根结底是等待其他线程对共享变量的修改），而等待就涉及到线程的挂起和唤醒。 基于此，AQS中有一个共享变量用于多线程间传递信息，并将各个线程对共享变量的修改抽象为了两个行为： 获取资源（acquire）：获取资源的结果直接关系到本线程的执行，如果成功，线程便可继续向下执行，否则，线程被挂起。 释放资源（release）：释放资源的行为不影响本线程的执行，但是如果归还成功，会尝试唤醒之前因为获取资源失败而挂起的其他线程，让其继续尝试获取资源。 至于 acquire 和 release 到底是对共享变量的什么操作（加或减，加1或加2）、acquire 和 release 行为结果的判定，就由继承了AQS的子类自己决定了。 此外，acquire 和 release 操作又分为了几种类型： 根据是否同时只能有一个线程acquire成功：独占的 或 共享的 根据挂起后是否可被interrupt唤醒：可被打断的 和 不可被打断的 根据挂起是否有超时时间：限时等待的 和 无限等待的 ReentrantLock采用的是独占模式，CountDownLatch和Semaphore采用的是共享模式，ReentrantReadWriteLock中，读锁采用共享模式，写锁采用独占模式。 AQS数据结构AQS的主要成员变量就三个： 123private transient volatile Node head;private transient volatile Node tail;private volatile int state; 其中 state 被称为同步状态或共享资源，而 head 、 tail 分别是同步队列的头、尾节点。 而通过Node内部类的数据结构： 123456789static final class Node &#123; ... volatile int waitStatus; volatile Node prev; volatile Node next; volatile Thread thread; Node nextWaiter; ...&#125; 我们可以看到，这个同步队列是个双向链表，且节点中还存储了线程实例。 也就是说，AQS的核心数据结构就是一个volatile共享变量和一个同步队列。 共享变量如之前所述，用于线程间传递信息。 同步队列则用于存储所有需要同步的线程，通过队列来管理线程的挂起和唤醒。 以ReentrantLock为引分析AQS的独占同步acqurie 操作首先我们以ReentrantLock的非公平加锁lock()为源头，来追踪 acquire 操作的调用链。 ReentrantLock类的lock()： 12345678910111213public class ReentrantLock implements Lock, java.io.Serializable &#123; ... private final Sync sync; abstract static class Sync extends AbstractQueuedSynchronizer &#123; ... &#125; ... public void lock() &#123; sync.lock(); &#125; ...&#125; 在 lock() 中调用了 sync 的 lock() 方法，其中 sync 是 ReentrantLock 的成员变量，类型是 Sync，而 Sync 是 ReentrantLock 的内部类，继承自 AQS 。 1234567/* Performs lock. Try immediate barge, backing up to normal acquire on failure. */final void lock() &#123; if (compareAndSetState(0, 1)) setExclusiveOwnerThread(Thread.currentThread()); else acquire(1);&#125; 而 sync 的 lock() 中，首先立刻尝试通过CAS操作将AQS中的state变量设为1，如果成功了，就将锁的持有者设置为本线程，也就是拿到锁了。 如果CAS失败了，表示state中的当前值不为0，那么有两种可能，一种是锁被其他线程持有，另一种是锁被本线程持有，因此，还需要继续往下执行 acquire() 方法。 acquire() 方法在 AQS 类中： 12345public final void acquire(int arg) &#123; if (!tryAcquire(arg) &amp;&amp; acquireQueued(addWaiter(Node.EXCLUSIVE), arg)) selfInterrupt();&#125; 在 if 判断中，首先执行 tryAcquire() 方法， 在AQS中，tryAcquire() 是个抽象方法，需要其子类自己实现，这就又回到了 ReentrantLock 的内部类 Sync 中： 123protected final boolean tryAcquire(int acquires) &#123; return nonfairTryAcquire(acquires);&#125; 123456789101112131415161718final boolean nonfairTryAcquire(int acquires) &#123; final Thread current = Thread.currentThread(); int c = getState(); if (c == 0) &#123; if (compareAndSetState(0, acquires)) &#123; setExclusiveOwnerThread(current); return true; &#125; &#125; else if (current == getExclusiveOwnerThread()) &#123; int nextc = c + acquires; if (nextc &lt; 0) // overflow throw new Error("Maximum lock count exceeded"); setState(nextc); return true; &#125; return false;&#125; 其中逻辑也很简单，如果 state 为0，表示锁是空闲的，尝试通过 CAS 操作将 state 设为1，若CAS操作成功，则成功获取锁，返回 true，否则返回 false。 如果 state 不为0，再判断锁的持有者是否是当前线程，如果是，那么可重入，成功获取锁，返回 true，否则的话，获取锁失败，返回 false。 我们再回过头来看acquire()： 12345public final void acquire(int arg) &#123; if (!tryAcquire(arg) &amp;&amp; acquireQueued(addWaiter(Node.EXCLUSIVE), arg)) selfInterrupt();&#125; 如果成功获取锁，返回的是ture，那么就直接跳出 if 判断，从acquire()方法中返回了，接着从 sync.lock 中返回，ReentrantLock 的 lock 方法就执行完了，成功获取到了锁，线程可以继续往下运行。 我们重点分析下 tryAcquire() 返回 false 的情况。 如果返回 false， 会继续执行 acquireQueued(addWaiter(Node.EXCLUSIVE), arg)， 其中 addWaiter() 是向队列中添加节点： 1234567891011121314151617181920212223242526272829303132private Node addWaiter(Node mode) &#123; Node node = new Node(Thread.currentThread(), mode); // 首先直接尝试通过CAS操作将新节点插入到队尾，失败了的话，再调用enq()方法入队 // 插入失败有两种可能：1. 队列尚未初始化 2. CAS失败，那就意味着有其他线程竞争 Node pred = tail; if (pred != null) &#123; // 判断队列头尾节点是否已经初始化完成 node.prev = pred; // ① if (compareAndSetTail(pred, node)) &#123; pred.next = node; return node; &#125; &#125; enq(node); return node;&#125;private Node enq(final Node node) &#123; // 死循环，直到新节点成功入队 for (;;) &#123; Node t = tail; if (t == null) &#123; // 如果没有初始化，首先初始化头尾节点 if (compareAndSetHead(new Node())) tail = head; &#125; else &#123; // 尝试将新节点入队 node.prev = t; if (compareAndSetTail(t, node)) &#123; t.next = node; return t; &#125; &#125; &#125;&#125; addWaiter() 方法中，首先尝试直接用CAS操作将新节点快速插入队尾，如果插入失败，就调用 enq() 方法，enq() 方法中通过循环CAS的方式保证插入成功才返回。 有两种可能会导入快速插入失败： 队列未初始化。队列的head和tail节点都是懒初始化的，也就是需要的时候才初始化。if (pred != null) 实际上是在判断队列是否已经初始化完成。初始化的过程在 enq() 方法中。 有线程竞争。 通过enq()中对队列的初始化过程，不难发现，队列的头结点实际上是个空节点，真正的有意义的节点从第二个开始。 还有一个细节①：将新节点插入队尾的时候，先将新节点的前序节点指向了tail，之后再通过CAS操作设置tail节点的值。细节我们最后再讨论，先梳理整体脉络。 入队后，就进入 acquireQueued 方法了： 123456789101112131415161718192021final boolean acquireQueued(final Node node, int arg) &#123; boolean failed = true; try &#123; boolean interrupted = false; for (;;) &#123; final Node p = node.predecessor(); if (p == head &amp;&amp; tryAcquire(arg)) &#123; // 如果排在第一个节点，尝试acquire setHead(node); p.next = null; // help GC failed = false; return interrupted; &#125; if (shouldParkAfterFailedAcquire(p, node) &amp;&amp; parkAndCheckInterrupt()) interrupted = true; &#125; &#125; finally &#123; if (failed) cancelAcquire(node); &#125;&#125; 首先看最外层的try{...}finally{...}，如果发生了异常，就取消acquire动作，实际上就是把该线程的节点从队列中删除，然后返回。 方法的主要逻辑是个 for (;;) 死循环，循环中的步骤： if (p == head &amp;&amp; tryAcquire(arg)) p是当前节点的前序节点，我们之前分析过，head是一个空节点，那么如果p是head，就表示当前节点是排在队列最前面的节点，根据 &amp;&amp; 的熔断原理，只有p == head条件满足，才会执行 tryAcquire 方法，尝试 acquire 操作，如果成功，那么本节点出队，从该方法返回，接着依次从 acquire() 方法、sync.lock() 方法、lock()方法返回，也就是获取锁成功，线程继续往下运行了。 如果不是排在第一个的节点，或者尝试 acquire 失败了，就需要执行 shouldParkAfterFailedAcquire 方法判断是否需要将线程挂起。 1234567891011121314private static boolean shouldParkAfterFailedAcquire(Node pred, Node node) &#123; int ws = pred.waitStatus; // 前序节点中的ws存储了本线程是否需要唤醒 if (ws == Node.SIGNAL) // 如果需要唤醒，直接返回ture，接下来就会挂起本线程 return true; if (ws &gt; 0) &#123; // 如果上一个节点已经无效了，删除上一个节点 do &#123; node.prev = pred = pred.prev; &#125; while (pred.waitStatus &gt; 0); pred.next = node; &#125; else &#123; // 如果前序节点中的ws是0，说明本节点是新插入的，将前序节点的ws设为SIGNAL compareAndSetWaitStatus(pred, ws, Node.SIGNAL); &#125; return false;&#125; 要理解这个方法，就要弄明白节点数据结构 Node 中 waitStatus 的含义，Node类中的注释解释的很详细： 12345static final int CANCELLED = 1;static final int SIGNAL = -1;static final int CONDITION = -2;static final int PROPAGATE = -3;volatile int waitStatus; waitStatus 是个int类型的变量，可能的取值有：1（CANCELLED），0（初始值），-1（SIGNAL），-2（CONDITION），-3（PROPAGATE）。 其中 CONDITION 只会在条件通知 Condition 中用到， 而 PROPAGATE 只会在共享同步中用到，对于我们现在分析的独占同步来说，waitStatus只有可能是： 0：初始值，acquire()中调用了addWaiter()，而addWaiter()中new Node(Thread.currentThread(), mode);，此时，节点的waitStatus就是0。 -1：SIGNAL，表示后序节点需要唤醒，注意是后续节点！这也是为什么需要一个空的头结点的原因，头节点中的waitStatus实际上指示了第一个有意义的节点中的线程是否需要唤醒。 1：CANCELLED，即本节点已经被取消了，无效了，需要删除。 了解了waitStatus的含义，我们再回头来看shouldParkAfterFailedAcquire方法，就很清晰明了了，首先查看前序节点中的waitState： 如果是SIGNAL，就直接返回ture，表示本线程需要挂起； 如果是CANCELLED，表示前序节点已经无效了，这里正式删除出队列； 如果是0，表示本节点是新插入，那么将前序节点的ws设为SIGNAL。 对于后两种情况，实际上是返回false的，但是别忘了这个函数外面还是个死循环呢，所以还会回来，终究会返回true的。 于是返回true。同样根据 &amp;&amp; 的熔断原理，parkAndCheckInterrupt() 方法就会执行。 1234private final boolean parkAndCheckInterrupt() &#123; LockSupport.park(this); return Thread.interrupted(); // ②&#125; parkAndCheckInterrupt方法非常简单，就是通过 LockSupport.park(this) 将本线程挂起。 也就是说，程序执行到这里，本线程就因为争抢锁失败而挂起了。 程序被唤醒，通常是由于其他线程释放了锁，执行了 release 操作，于是，程序继续从 return Thread.interrupted(); 处执行，并从parkAndCheckInterrupt() 方法中返回。 这里还有个细节②：调用 Thread.interrupted()方法查询当前线程的中断标志后，会把中断标志清除。 继续 for(;;) 循环，也就是回到了步骤1。 至此，AQS中的 acquire 操作就基本梳理清楚了： AQS中对state的实际修改如何在子类中实现的：通过 tryAcquire 抽象方法 AQS如何判断 acquire 操作是否成功：还是通过 tryAcquire 抽象方法 AQS如何通过消息队列管理线程，将线程挂起 release操作release操作相对就简单多了。 从 ReentrantLock 的 unlock() 方法开始追踪： 123public void unlock() &#123; sync.release(1);&#125; 123456789public final boolean release(int arg) &#123; if (tryRelease(arg)) &#123; Node h = head; if (h != null &amp;&amp; h.waitStatus != 0) unparkSuccessor(h); return true; &#125; return false;&#125; tryRelease 同样是抽象方法，由子类实现。这里是 ReentrantLock 的逻辑，比较好理解，就不多解释了。 123456789101112protected final boolean tryRelease(int releases) &#123; int c = getState() - releases; if (Thread.currentThread() != getExclusiveOwnerThread()) throw new IllegalMonitorStateException(); boolean free = false; if (c == 0) &#123; free = true; setExclusiveOwnerThread(null); &#125; setState(c); return free;&#125; 接下来回头继续看 release() 方法，判断 if (h != null &amp;&amp; h.waitStatus != 0)，这是在判断队列中是否有节点，如果有节点，就唤醒第一个节点（即头结点的后序节点）：unparkSuccessor(h) 123456789101112131415private void unparkSuccessor(Node node) &#123; // 这里node就是head，头结点 int ws = node.waitStatus; if (ws &lt; 0) compareAndSetWaitStatus(node, ws, 0); Node s = node.next; // 直接取出头结点的后序节点 if (s == null || s.waitStatus &gt; 0) &#123; // 如果head的后序节点无效，那么从tail尾节点往前找，找到队列最前面的节点 s = null; for (Node t = tail; t != null &amp;&amp; t != node; t = t.prev) // ③ if (t.waitStatus &lt;= 0) s = t; &#125; if (s != null) LockSupport.unpark(s.thread);&#125; unparkSuccessor() 就是唤醒队列排最前面的线程，但是这里面也是有个细节③：为什么头节点的后序节点可能无效？为什么要从尾节点往前找？ 细节：① ：AddWaiter() 方法中，将新节点插入队尾的时候，为何先将新节点的前序节点指向了tail，之后再通过CAS操作设置tail节点的值？ 首先明确一下插入节点的三个动作： A. 将原tail节点的 next 指向新节点 B. 将新节点的 prev 指向原tail节点 C. 将tail节点指向新节点，这一步是CAS操作。 其次，我们需要明白这个操作可能发生在高并发竞争下，即可能同时有多个线程调用AddWaiter()尝试添加新节点。 那么，A肯定不能在C之前执行，因为CAS是可能失败的，如果线程1和线程2同时调用AddWaiter()，线程1先执行了A，接着线程2执行了A，然后线程1执行C成功，而线程2执行C失败了，这样，原tail的next节点本应该指向线程1节点的，但实际上却指向了线程2节点。 于是只剩下了 C -&gt; A -&gt; B，C -&gt; B -&gt; A，A -&gt; C -&gt; B 其实C -&gt; A -&gt; B 和 C -&gt; B -&gt; A是一样的，所以一起讨论，这种顺序有没有问题呢？ 乍一看，多个线程同时AddWaiter()肯定是没问题了，但是如果一个线程在AddWaiter()且恰好执行完C，但A和B还没有执行，而另一个线程在unparkSuccessor唤醒呢？这时候，tail节点已经指向新节点了，但是从head正序遍历是找不到新节点的，而新节点也找不到其前序节点，而唤醒条件waitState却需要从前序节点中取，因此，在高并发下也是有问题的。 而A -&gt; C -&gt; B的顺序，则至少保证了，只要tail节点的值更新了，那么其前序节点一定是有效的。实际上这也解释了细节③。 我们这就看看细节③：unparkSuccessor中为什么头节点的后序节点可能无效？为什么要从尾节点往前找？ 正如细节①所述，A -&gt; C -&gt; B 的执行顺序下，高并发下，从head往后遍历不一定是可靠的，可能原tail节点的next还没有来得及指向新节点。但是prev节点一定是可靠的，所以优先尝试往后找，如果找不到，就从tail往前找。 ②：parkAndCheckInterrupt为何要调用 Thread.interrupted()？该方法查询当前线程的中断标志后，会把中断标志清除。 同时，我们注意到，在acquire方法中，如果发现是中断唤醒的，还会用selfInterrupt()补上中断标志。 12345public final void acquire(int arg) &#123; if (!tryAcquire(arg) &amp;&amp; acquireQueued(addWaiter(Node.EXCLUSIVE), arg)) selfInterrupt();&#125; 这不是多此一举吗？明明可以调用不清中断标志位的isInterrupted()方法。 原因就在于，如果不把中断标志清除，调用park()方法是不会挂起线程的。由于park()是native方法，就需要去Hotspot代码中去求证了，这里就不赘述了。 以CountDownLatch为引分析AQS的共享同步acquire操作我们最开始就分析过，acquire操作失败会导致线程挂起，因此我们从CountDownLatch的await()方法开始追踪： 123public void await() throws InterruptedException &#123; sync.acquireSharedInterruptibly(1);&#125; 和ReentrantLock一样，sync的类型是Sync，也是一个内部类，继承自AQS： 1234567public class CountDownLatch &#123; private static final class Sync extends AbstractQueuedSynchronizer &#123; ... &#125; private final Sync sync; ...&#125; 我们继续看 sync.acquireSharedInterruptibly()，这是个AQS中的方法： 123456public final void acquireSharedInterruptibly(int arg) throws InterruptedException &#123; if (Thread.interrupted()) throw new InterruptedException(); if (tryAcquireShared(arg) &lt; 0) doAcquireSharedInterruptibly(arg);&#125; 和独占同步类似，tryAcquireShared()也是个抽象方法，由子类CountDownLatch的内部类Sync实现，其中定义了对共享变量state的操作，以及acquire的结果： 123protected int tryAcquireShared(int acquires) &#123; return (getState() == 0) ? 1 : -1;&#125; 但和独占同步的 tryAcquire()方法不同的是，tryAcquire() 方法返回Boolean类型，true是成功，false是失败；而 tryAcquireShared() 方法返回的是int，负数表示失败，0表示成功但已经没有可用资源，正数表示成功且仍有可用资源。 如果acquire成功的话，就会依次从acquireSharedInterruptibly()、await()方法返回，线程也就继续往下运行了。 如果acquire失败，就会执行 doAcquireSharedInterruptibly() 方法： 123456789101112131415161718192021222324private void doAcquireSharedInterruptibly(int arg) throws InterruptedException &#123; final Node node = addWaiter(Node.SHARED); boolean failed = true; try &#123; for (;;) &#123; final Node p = node.predecessor(); if (p == head) &#123; // 判断是否排在同步队列最前面 int r = tryAcquireShared(arg); // 尝试获取同步资源 if (r &gt;= 0) &#123; setHeadAndPropagate(node, r); p.next = null; // help GC failed = false; return; &#125; &#125; if (shouldParkAfterFailedAcquire(p, node) &amp;&amp; parkAndCheckInterrupt()) throw new InterruptedException(); &#125; &#125; finally &#123; if (failed) cancelAcquire(node); &#125;&#125; 和独占acquire的逻辑几乎一样：一个for(;;)死循环，循环中首先判断是否排在同步队列最前面，如果是，则尝试acquire，如果acquire成功了，那么就跳出循环，线程继续往下运行，如果acquire失败，就再次把线程挂起。 不同点就在于: 1234567int r = tryAcquireShared(arg);if (r &gt;= 0) &#123; setHeadAndPropagate(node, r); p.next = null; // help GC failed = false; return;&#125; setHeadAndPropagate() 方法中会判断传入的变量 r，也就是 tryAcquireShared() 方法的返回值，如果大于0（即仍然有共享资源可以acquire），就会再调用一次 doReleaseShared()，唤醒下一个线程尝试 acquire。 release操作从 CountDownLatch 的 countDown() 方法追踪： 123public void countDown() &#123; sync.releaseShared(1);&#125; AQS中的releaseShared()： 1234567public final boolean releaseShared(int arg) &#123; if (tryReleaseShared(arg)) &#123; doReleaseShared(); return true; &#125; return false;&#125; 同样，tryReleaseShared()方法由子类实现： 1234567891011protected boolean tryReleaseShared(int releases) &#123; // Decrement count; signal when transition to zero for (;;) &#123; int c = getState(); if (c == 0) return false; int nextc = c-1; if (compareAndSetState(c, nextc)) return nextc == 0; &#125;&#125; 最后来看 doReleaseShared() 方法： 1234567891011121314151617private void doReleaseShared() &#123; for (;;) &#123; Node h = head; if (h != null &amp;&amp; h != tail) &#123; int ws = h.waitStatus; if (ws == Node.SIGNAL) &#123; if (!compareAndSetWaitStatus(h, Node.SIGNAL, 0)) continue; // loop to recheck cases unparkSuccessor(h); &#125; else if (ws == 0 &amp;&amp; !compareAndSetWaitStatus(h, 0, Node.PROPAGATE)) continue; // loop on failed CAS &#125; if (h == head) // loop if head changed break; &#125;&#125;]]></content>
      <categories>
        <category>多线程</category>
      </categories>
      <tags>
        <tag>多线程</tag>
        <tag>AQS</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[多线程-JUC中的同步工具]]></title>
    <url>%2F2021%2F01%2F06%2F%E5%A4%9A%E7%BA%BF%E7%A8%8B-AQS1%2F</url>
    <content type="text"><![CDATA[前言相信JUC和AQS都是大家如雷贯耳、耳熟能详的词儿了。 JUC是大名鼎鼎的java.util.concurrent包的缩写，一看名字就很牛，java提供的并发工具集。而AQS（Abstract Queued Synchronizer）则是JUC包中许多同步工具实现的基础。 我们先来看看JUC包中有哪些东西： atomic原子类：著名的基于CAS的原子操作类。 并发容器：包括ConcurrentMap、ConcurrentSkipListSet、CopyOnWriteArraySet、ConcurrentLinkedQueue、Dequeue等等。而创建线程池的一个重要参数：workQueue，一般就出自这里。 线程池： 异步机制常用的Future、Callable 线程池ThreadPoolExecutor以及四种预定义的线程池SingleThreadExecutor、CachedThreaadPool、FixedThreadPool、SecheduledThreadPool 同步工具 AQS Lock：ReentrantLock、ReadWriteLock、LockSupport 其他工具：CountDownLatch、CyclicBarrier、Phaser、Semaphore、Exchanger 几乎囊括了所有和多线程相关的内容。 本文我们先来总结一下JUC中的同步工具。 LockSupportLockSupport中提供的方法不多，且都是以静态方法提供： 12345678public static void unpark(Thread thread);public static void park(Object blocker);public static void parkNanos(Object blocker, long nanos);public static void parkUntil(Object blocker, long deadline);public static Object getBlocker(Thread t);public static void park();public static void parkNanos(long nanos);public static void parkUntil(long deadline); 说白了就是将Unsafe类中的 park() 和 unpark() 方法包装了一下，提供了挂起和唤醒线程的方法。 为啥要包装呢？ 因为Unsafe类并不是普通应用代码可以直接调用的，看下Unsafe的源码： 1234567891011private Unsafe() &#123;&#125;private static final Unsafe theUnsafe = new Unsafe();@CallerSensitivepublic static Unsafe getUnsafe() &#123; Class&lt;?&gt; caller = Reflection.getCallerClass(); if (!VM.isSystemDomainLoader(caller.getClassLoader())) throw new SecurityException("Unsafe"); return theUnsafe;&#125; 可以看到： Unsafe是单例的，外界无法通过构造方法直接构造Unsafe对象，需要调用 getUnsafe() 方法获取。 getUnsafe() 方法中是有条件的，调用者必须是 Bootstrap类加载器 加载的类（比如AQS），否则会报Unsafe异常，显然我们写的普通代码是无法调用的。 因此，一般情况下，我们写的代码是无法直接调用Unsafe类中的方法的。 当然，也不是完全没有办法，比如我们可以通过反射，获取 theUnsafe 方法： 123final Field field = Unsafe.class.getDeclaredField("theUnsafe");field.setAccessible(true);unsafe = (Unsafe) field.get(null); 但这毕竟不是官方推荐的方法，因此，LockSupport便将 park() 和 unpark() 方法包装了一下，提供给普通应用程序使用。 LockReentrantLock通过类名就能看出来，这是一把可重入锁。 常用方法12345678910/* 构造方法 */public ReentrantLock(boolean fair);public ReentrantLock();/* 加锁 */public void lock();public void lockInterruptibly();public boolean tryLock();public boolean tryLock(long timeout, TimeUnit unit);/* 解锁 */public void unlock(); ReentrantReadWriteLock其他同步工具CountDownLatch从类名来看，这是个向下计数的门栓。初始化时，传入计数初始值，调用await()的线程挂起等待，其他线程每调用一次countDown()，计数值减一，当计数值减到0，调用await()的方法被唤醒继续执行。 常用方法12345678/* 构造方法 */public CountDownLatch(int count);/* 等待 */public void await();public boolean await(long timeout, TimeUnit unit);/* 计数相关 */public void countDown();public long getCount(); 举例123456789101112131415161718192021222324252627282930public class T06_TestCountDownLatch &#123; public static void main(String[] args) &#123; Thread[] threads = new Thread[10]; CountDownLatch latch = new CountDownLatch(threads.length); for(int i=0; i&lt;threads.length; i++) &#123; threads[i] = new Thread(()-&gt;&#123; try &#123; Thread.sleep((new Random().nextInt(9) + 1) * 1000); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; latch.countDown(); System.out.println(Thread.currentThread().getName() + " count down."); &#125;, "T" + i); &#125; for (Thread thread : threads) &#123; thread.start(); &#125; System.out.println("Waiting latch..."); try &#123; latch.await(); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; System.out.println("End latch");&#125; 输出： 123456789101112Waiting latch...T5 count down.T7 count down.T4 count down.T6 count down.T1 count down.T3 count down.T9 count down.T8 count down.T2 count down.T0 count down.End latch CyclicBarrierCyclicBarrier是个计数拦截器，创建CyclicBarrier时，需要传入计数初始值。每个线程调用wait()方法，将线程挂起。直到调用wait()的线程数达到计数值，所有线程一起唤醒。 常用方法123456/* 构造方法 */public CyclicBarrier(int parties, Runnable barrierAction);public CyclicBarrier(int parties);/* 等待 */public int await();public int await(long timeout, TimeUnit unit); 举例1234567891011121314151617public class TestCyclicBarrier &#123; public static void main(String[] args) &#123; CyclicBarrier barrier = new CyclicBarrier(10, () -&gt; System.out.println("满人")); for(int i = 0; i &lt; 10; i++) &#123; new Thread(()-&gt;&#123; try &#123; System.out.println(Thread.currentThread().getName() + " waiting..."); barrier.await(); System.out.println(Thread.currentThread().getName() + " finish."); &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; &#125;).start(); &#125; &#125;&#125; 输出： 123456789101112131415161718192021Thread-0 waiting...Thread-4 waiting...Thread-5 waiting...Thread-3 waiting...Thread-6 waiting...Thread-2 waiting...Thread-1 waiting...Thread-8 waiting...Thread-7 waiting...Thread-9 waiting...满人Thread-6 finish.Thread-0 finish.Thread-7 finish.Thread-5 finish.Thread-8 finish.Thread-3 finish.Thread-1 finish.Thread-2 finish.Thread-4 finish.Thread-9 finish. Phaser常用方法12345678910111213141516/* 构造方法 */public Phaser();public Phaser(int parties);public Phaser(Phaser parent);public Phaser(Phaser parent, int parties);public int register();public int bulkRegister(int parties);public int arrive();public int arriveAndDeregister();public int arriveAndAwaitAdvance();public int awaitAdvance(int phase);public int awaitAdvanceInterruptibly(int phase);public int awaitAdvanceInterruptibly(int phase, long timeout, TimeUnit unit); Semaphore信号量，和锁的区别是，锁只能允许一个线程进入同步代码段，但是信号量可以允许多个线程进入同步代码段。 常用方法1234567891011121314151617/* 构造方法 */public Semaphore(int permits);public Semaphore(int permits, boolean fair);/* 获取单个许可 */public void acquire();public void acquireUninterruptibly();public boolean tryAcquire();public boolean tryAcquire(long timeout, TimeUnit unit);/* 释放单个许可 */public void release();/* 获取多个许可 */public void acquire(int permits);public void acquireUninterruptibly(int permits);public boolean tryAcquire(int permits);public boolean tryAcquire(int permits, long timeout, TimeUnit unit);/* 释放多个许可 */public void release(int permits); 举例12345678910111213141516171819202122232425262728293031public class TestSemaphore &#123; /* 允许两个线程同时运行 */ static Semaphore s = new Semaphore(2, true); static class MyRunnable implements Runnable &#123; @Override public void run() &#123; String name = Thread.currentThread().getName(); try &#123; s.acquire(); System.out.println(name + " running..."); Thread.sleep(500); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; finally &#123; System.out.println(name + " finish."); s.release(); &#125; &#125; &#125; public static void main(String[] args) &#123; new Thread(new MyRunnable(), "T1").start(); new Thread(new MyRunnable(), "T2").start(); new Thread(new MyRunnable(), "T3").start(); new Thread(new MyRunnable(), "T4").start(); new Thread(new MyRunnable(), "T5").start(); new Thread(new MyRunnable(), "T6").start(); &#125;&#125; 输出： 123456789101112T1 running...T2 running...T2 finish.T1 finish.T3 running...T4 running...T3 finish.T4 finish.T5 running...T6 running...T5 finish.T6 finish. ExchangerExchanger就如其类名，用于线程之间交换数据。 常用方法12345/* 构造方法 */public Exchanger();/* 交换数据 */public V exchange(V x);public V exchange(V x, long timeout, TimeUnit unit); 举例123456789101112131415161718192021222324252627282930313233public class TestExchanger &#123; static Exchanger&lt;String&gt; exchanger = new Exchanger&lt;&gt;(); public static void main(String[] args) &#123; new Thread(()-&gt;&#123; String s = "T1"; System.out.println("t1 ready to exchange..."); try &#123; s = exchanger.exchange(s); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; System.out.println(Thread.currentThread().getName() + ": " + s); &#125;, "t1").start(); new Thread(()-&gt;&#123; String s = "T2"; System.out.println("t2 waiting 3 sec..."); try &#123; Thread.sleep(3000); System.out.println("t2 ready to exchange..."); s = exchanger.exchange(s); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; System.out.println(Thread.currentThread().getName() + ": " + s); &#125;, "t2").start(); &#125;&#125; 输出： 12345t1 ready to exchange...t2 waiting 3 sec...t2 ready to exchange...t2: T1t1: T2 实现]]></content>
      <categories>
        <category>多线程</category>
      </categories>
      <tags>
        <tag>多线程</tag>
        <tag>AQS</tag>
        <tag>ReentrantLock</tag>
        <tag>CountDownLatch</tag>
        <tag>CyclicBarrier</tag>
        <tag>Phaser</tag>
        <tag>ReadWriteLock</tag>
        <tag>Semaphore</tag>
        <tag>Exchanger</tag>
        <tag>LockSupport</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[多线程-synchronized底层实现]]></title>
    <url>%2F2021%2F01%2F03%2F%E5%A4%9A%E7%BA%BF%E7%A8%8B-synchronized%2F</url>
    <content type="text"><![CDATA[前言synchronized在JDK1.6的优化之后，性能上有了较大的提升。 synchronized优化的内容是锁升级机制。 偏向锁、自旋锁、重量级锁 锁升级条件、过程 底层实现 各类锁的含义JDK1.6之后，synchronized的锁机制按照开销从小到大排列，依次可分为：偏向锁、自旋锁（轻量级锁）和重量级锁。 重量级锁 JDK1.6之前，synchronized只有一种锁机制，即重量级锁。 获取锁失败的线程会进入阻塞（Blocked）状态，目标锁的释放会唤醒这些线程。 线程的阻塞和唤醒都需要通过系统调用，由操作系统来完成，其中涉及到用户态与内核态的切换，开销很大。这也是通常来说重量级锁性能较低的原因。 自旋锁 通过CAS操作来获取锁，如果CAS操作成功，则获取到锁，如果失败，则继续自旋尝试获取锁。 获取锁失败的线程不会阻塞，仍然继续自旋尝试获取锁。 自旋锁的加锁和解锁不涉及线程状态的变化，CAS操作也不要系统调用，因此，相比于重量级锁，节省了系统调用的开销。 偏向锁 偏向锁只存在于仅有一个线程请求锁的情况下，一旦超过一个线程请求锁，则锁升级为自旋锁。 偏向锁仅在该线程第一次获取锁时，通过CAS操作在锁上记录线程标识，之后再尝试获取锁时，如果发现锁上的线程标识和本线程相符，直接进入同步代码块，无需再通过CAS操作加锁。退出同步代码块也无需释放锁操作。 引入偏向锁的原因是：Hotspot作者经研究发现，大多数情况下，锁不仅不存在多线程竞争，还总是由同一个线程多次获得，因而通过引入偏向锁，能够让这种情况下的加锁解锁操作开销进一步降低。 思考 偏向锁一定比自旋锁高效吗？ 不一定，偏向锁是针对无竞争且每次是由同一个线程获取锁的情况的优化。如果明确知道存在竞争，那么偏向锁的设置和撤销就是无意义的消耗，不如直接升级为自旋锁。 自旋锁一定比重量级锁高效吗？ 不一定，重量级锁的开销在于加锁和解锁过程的系统调用开销，对于重量级锁，加锁失败的线程进入Blocked状态，不再占用CPU资源。 而对于自旋锁，加锁失败的线程一直处于Runnable状态，会一直自旋再次尝试获取锁。 因此，如果竞争很激烈（即有很多线程尝试获取锁），或同步代码段执行的时间非常长（即加锁失败的线程需要长时间自旋等待），那么加锁失败线程的自旋就会消耗大量CPU资源，也就得不偿失了。 上面的两个问题就引出了锁升级的概念。 锁升级synchronized锁升级过程如下图所示： 偏向锁功能在JVM中有两个相关参数可以配置： -XX:-UseBiasedLocking=ture ：是否使用偏向锁，默认开启。 -XX:BiasedLockingStartupDelay=4000 ：偏向锁功能开启延时，默认4000，即JVM启动4秒后，才开启偏向锁功能。 之所以默认配置了4秒的开启延时，是因为，在JVM启动过程中，明确知晓存在很多竞争，为了避免偏向锁撤销和锁升级带来的无意义的消耗，因此延时一段时间，等JVM启动完成后，才开启偏向锁功能。 一个锁对象new出来之后，如果未开启偏向锁功能，那么这就是一个普通对象，而如果开启了偏向锁功能，此时锁上没有任何一个线程标识，称之为匿名偏向。 普通对象加锁后，即成为自旋锁；匿名偏向锁加锁后，成为偏向锁。 偏向锁不可重偏向，一旦有第二个线程尝试对偏向锁加锁，偏向锁便撤销，并升级为自旋锁。 如果竞争加剧，自旋锁升级为重量级锁。 何为竞争加剧： 某个线程自旋次数超过指定值，可通过 -XX:PreBlcokSpin=10 配置，默认值为10。 或者自旋等待该锁的进程超过指定值，一般为CPU核数的一半。 自适应自旋（Adapative Self Spinning）：两个条件的阈值由JVM自己动态控制。 底层实现了解上面锁的类型和升级过程之后，我们可能还会有疑问： 为什么synchronized可以将任何对象作为锁？ 怎么区分一个锁对象是何种类型的锁？ 偏向锁的线程标识存的是什么？存在哪儿？ synchronized可重入是如何实现的？ …… 这就需要了解Synchronized更底层的实现了。 java对象内存布局首先了解一下HotSpot实现中，一个java对象（Object）在内存中的布局。 内存布局如下表所示，一个对象在内存中通常可以分为以下4部分：mark word、class pointer、instance data和内存对齐。 内容 大小 备注 mark word 8字节 class pointer 4字节 指向对象所属的类 instance data 对象中的成员所占的空间 内存对齐 0~7字节 8字节对齐 其中mark word中的内容和锁紧密相关。 mark wordmark word占用8字节空间，其中的内容随着对象状态的不同而变化，如下表所示： 可以看到根据一个对象的最后3位，就能判断出此对象当前是普通对象、正在被垃圾回收还是处于某种锁状态。 可重入可重入锁是指：同一个线程可以多次对同一把锁执行加锁操作，而不会引起死锁。 synchronized锁必须是可重入的，否则某些java特性就会引发死锁，比如：父类中有个synchronized方法，子类重写了该方法，也是synchronized方法，子类的方法中又通过super调用了父类的该方法，相当于对同一把锁加锁了两次，如果synchronized不支持重入，那么这种情况就会引发死锁。 那么，synchronized是如何实现可重入的呢？ 关键在于记录两个东西： 线程的标识，否则无法判断是否是同一个线程加锁； 加锁的次数，因为需要对应次数的解锁才能释放锁。 接下来我们就来看看不同的锁分别是如何实现的： 偏向锁 mark word中就记录了线程指针 不需要记录加锁次数，因为偏向锁不存在释放锁的概念，一旦有其他线程尝试拿锁，就会升级为自旋锁。 自旋锁 通过Lock Record来实现重入。 Lock Record在Hot Spot源码中的class名称是BasicLock，其中只有一个成员 _displaced_header，用于备份该对象加锁前的mark word。 Lock Record 和 加锁的对象 成对以BasicObjectLock的结构存储在线程栈中，每加一次锁，都会向栈中存入一个Lock Record。 从mark word的内存布局可以看到，当锁标志是00时，mark word中记录了Lock Record的指针，再次加锁时会通过 is_lock_owned 函数判断对象mark word中的Lock Record指针是否在本线程的栈中，如果是，则表示锁是本线程持有的。 自旋锁并没有通过记录加锁的次数来实现解锁和加锁次数的对应。自旋锁通过以下方法实现： 第一次加锁时，会把对象的mark word中的原内容备份到Lock Record的displaced header中，并通过CAS的方式修改mark word，将Lock Record的地址存入mark word中。 之后，当同一个线程再次加锁时，会生成新的Lock Record放入栈中，但是displaced header中存的是NULL，也不会再修改mark word。 解锁时，如果从栈中弹出的Lock Record中的displaced header中存的是NULL，就表示锁还没有解完，锁仍然还由本线程持有。 直到弹出的Lock Record中，displaced header中内容不为NULL，将displaced header中的内容还原到对象的mark word中，锁成功释放。 重量级锁 重量级锁通过ObjectMonitor实现。 ObjectMonitor中记录了锁的持有线程_owner和重入的次数_recursions。 此外，ObjectMonitor还备份了对象加锁前的mark word，即_header。 HashCode一旦某个对象计算过identity hashcode，该值就会存储在对象的mark word中，下次再需要获取该对象的hashcode时，就直接返回mark word中记录的hashcode。 但是从markword的布局图中，我们看到，对象被加锁后，mark word中就不再存有hashcode了，难道加锁的对象就没有hashcode了吗？ 答案显然是否定的。 对于自旋锁和重量级锁，hashcode可以从LockRecod或者ObjectMonitor中的displaced header中读出。 而对于偏向锁，实际上偏向锁和hashcode不能共存，一旦对处于偏向锁状态的对象计算hashcode，如果偏向锁未被持有，那么会变为普通对象，如果偏向锁被持有了，则膨胀为自旋锁或重量级锁。 实验验证想要通过实验验证锁的升级过程，就需要能够直观的看到一个对象在内存中的原始数值，通过 ClassLayout 类可以将一个java对象在内存中的原始数据以方便观察的格式打印出来。使用方法也很简单： 引入mvn依赖： 12345&lt;dependency&gt; &lt;groupId&gt;org.openjdk.jol&lt;/groupId&gt; &lt;artifactId&gt;jol-core&lt;/artifactId&gt; &lt;version&gt;0.9&lt;/version&gt;&lt;/dependency&gt; 在源码中输出： 1System.out.println(ClassLayout.parseInstance(obj).toPrintable()); 普通对象 加锁 -&gt; 自旋锁代码如下： 123456789101112131415public class T01_Synchronized &#123; public static void main(String[] args) throws InterruptedException &#123; Object lock = new Object(); System.out.println(ClassLayout.parseInstance(lock).toPrintable()); synchronized (lock) &#123; System.out.println(ClassLayout.parseInstance(lock).toPrintable()); synchronized (lock) &#123; System.out.println(ClassLayout.parseInstance(lock).toPrintable()); &#125; &#125; &#125;&#125; 分别打印了一个Object实例在加锁前后的内存布局。 输出如下： 1234567891011121314151617181920212223242526java.lang.Object object internals: OFFSET SIZE TYPE DESCRIPTION VALUE 0 4 (object header) 01 00 00 00 (00000001 00000000 00000000 00000000) (1) 4 4 (object header) 00 00 00 00 (00000000 00000000 00000000 00000000) (0) 8 4 (object header) e5 01 00 f8 (11100101 00000001 00000000 11111000) (-134217243) 12 4 (loss due to the next object alignment)Instance size: 16 bytesSpace losses: 0 bytes internal + 4 bytes external = 4 bytes totaljava.lang.Object object internals: OFFSET SIZE TYPE DESCRIPTION VALUE 0 4 (object header) 38 f6 e6 02 (00111000 11110110 11100110 00000010) (48690744) 4 4 (object header) 00 00 00 00 (00000000 00000000 00000000 00000000) (0) 8 4 (object header) e5 01 00 f8 (11100101 00000001 00000000 11111000) (-134217243) 12 4 (loss due to the next object alignment)Instance size: 16 bytesSpace losses: 0 bytes internal + 4 bytes external = 4 bytes totaljava.lang.Object object internals: OFFSET SIZE TYPE DESCRIPTION VALUE 0 4 (object header) 38 f6 e6 02 (00111000 11110110 11100110 00000010) (48690744) 4 4 (object header) 00 00 00 00 (00000000 00000000 00000000 00000000) (0) 8 4 (object header) e5 01 00 f8 (11100101 00000001 00000000 11111000) (-134217243) 12 4 (loss due to the next object alignment)Instance size: 16 bytesSpace losses: 0 bytes internal + 4 bytes external = 4 bytes total 我们看到打印出的lock对象的内存布局，每行展示了4字节数据，VALUE一栏分别以16进制、2进制和10进制三种方式打印出了值。 前两行共8字节，就是mark word的值，打印是按低字节在前的顺序打印的，因此第一个字节的bit0~1就是锁标志。 可以看到加锁前，锁标志是 0 1，偏向锁位是 0，其他位都是0，即这是一个普通对象，之所以不是匿名偏向锁，是因为程序刚运行时，偏向锁功能还未启用。 加锁后，锁标志变成了0 0，即自旋锁，且其他位已经有数据，其中存储的是Lock Record的地址。 再次加锁，程序仍然能继续执行，证明synchronized是可重入的，且mark word中存储的Lock Record地址仍然是初次加锁的Lock Record地址，并没有变。 匿名偏向 加锁 -&gt; 偏向锁1234567891011121314public class T01_Synchronized &#123; public static void main(String[] args) throws InterruptedException &#123; Thread.sleep(5000); Object lock = new Object(); System.out.println(ClassLayout.parseInstance(lock).toPrintable()); synchronized (lock) &#123; System.out.println(ClassLayout.parseInstance(lock).toPrintable()); &#125; &#125;&#125; 输出如下： 1234567891011121314151617java.lang.Object object internals: OFFSET SIZE TYPE DESCRIPTION VALUE 0 4 (object header) 05 00 00 00 (00000101 00000000 00000000 00000000) (5) 4 4 (object header) 00 00 00 00 (00000000 00000000 00000000 00000000) (0) 8 4 (object header) e5 01 00 f8 (11100101 00000001 00000000 11111000) (-134217243) 12 4 (loss due to the next object alignment)Instance size: 16 bytesSpace losses: 0 bytes internal + 4 bytes external = 4 bytes totaljava.lang.Object object internals: OFFSET SIZE TYPE DESCRIPTION VALUE 0 4 (object header) 05 38 a6 02 (00000101 00111000 10100110 00000010) (44447749) 4 4 (object header) 00 00 00 00 (00000000 00000000 00000000 00000000) (0) 8 4 (object header) e5 01 00 f8 (11100101 00000001 00000000 11111000) (-134217243) 12 4 (loss due to the next object alignment)Instance size: 16 bytesSpace losses: 0 bytes internal + 4 bytes external = 4 bytes total 这次首先sleep 5秒，待偏向锁功能启用后，再new一个Object，打印加锁前后，该对象的内存布局。 可见，加锁前，锁标志为：0 1，偏向锁位为：1，markword中其余位均为0，为匿名偏向状态。 加锁后，mark word 中记录了线程指针（JavaThread *）。 偏向锁与hashcode12345678910111213141516171819202122232425262728public class T01_Synchronized &#123; public static void main(String[] args) throws InterruptedException &#123; Thread.sleep(5000); Object lock = new Object(); System.out.println(ClassLayout.parseInstance(lock).toPrintable()); Integer i = lock.hashCode(); System.out.println("HashCode: " + Integer.toHexString(i)); System.out.println(ClassLayout.parseInstance(lock).toPrintable()); synchronized (lock) &#123; System.out.println(ClassLayout.parseInstance(lock).toPrintable()); &#125; Object lock2 = new Object(); System.out.println(ClassLayout.parseInstance(lock2).toPrintable()); synchronized (lock2) &#123; System.out.println(ClassLayout.parseInstance(lock2).toPrintable()); i = lock2.hashCode(); System.out.println("HashCode: " + Integer.toHexString(i)); System.out.println(ClassLayout.parseInstance(lock2).toPrintable()); &#125; &#125;&#125; 首先产生一把匿名偏向锁，接着对该对象计算hashcode，观察前后对象内存布局； 再生成一把偏向锁，加锁后计算该对象的hashcode，观察前后对象布局。 输出如下： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455java.lang.Object object internals: OFFSET SIZE TYPE DESCRIPTION VALUE 0 4 (object header) 05 00 00 00 (00000101 00000000 00000000 00000000) (5) 4 4 (object header) 00 00 00 00 (00000000 00000000 00000000 00000000) (0) 8 4 (object header) e5 01 00 f8 (11100101 00000001 00000000 11111000) (-134217243) 12 4 (loss due to the next object alignment)Instance size: 16 bytesSpace losses: 0 bytes internal + 4 bytes external = 4 bytes totalHashCode: 28ba21f3java.lang.Object object internals: OFFSET SIZE TYPE DESCRIPTION VALUE 0 4 (object header) 01 f3 21 ba (00000001 11110011 00100001 10111010) (-1172180223) 4 4 (object header) 28 00 00 00 (00101000 00000000 00000000 00000000) (40) 8 4 (object header) e5 01 00 f8 (11100101 00000001 00000000 11111000) (-134217243) 12 4 (loss due to the next object alignment)Instance size: 16 bytesSpace losses: 0 bytes internal + 4 bytes external = 4 bytes totaljava.lang.Object object internals: OFFSET SIZE TYPE DESCRIPTION VALUE 0 4 (object header) d8 f5 11 03 (11011000 11110101 00010001 00000011) (51508696) 4 4 (object header) 00 00 00 00 (00000000 00000000 00000000 00000000) (0) 8 4 (object header) e5 01 00 f8 (11100101 00000001 00000000 11111000) (-134217243) 12 4 (loss due to the next object alignment)Instance size: 16 bytesSpace losses: 0 bytes internal + 4 bytes external = 4 bytes totaljava.lang.Object object internals: OFFSET SIZE TYPE DESCRIPTION VALUE 0 4 (object header) 05 00 00 00 (00000101 00000000 00000000 00000000) (5) 4 4 (object header) 00 00 00 00 (00000000 00000000 00000000 00000000) (0) 8 4 (object header) e5 01 00 f8 (11100101 00000001 00000000 11111000) (-134217243) 12 4 (loss due to the next object alignment)Instance size: 16 bytesSpace losses: 0 bytes internal + 4 bytes external = 4 bytes totaljava.lang.Object object internals: OFFSET SIZE TYPE DESCRIPTION VALUE 0 4 (object header) 05 38 2e 03 (00000101 00111000 00101110 00000011) (53360645) 4 4 (object header) 00 00 00 00 (00000000 00000000 00000000 00000000) (0) 8 4 (object header) e5 01 00 f8 (11100101 00000001 00000000 11111000) (-134217243) 12 4 (loss due to the next object alignment)Instance size: 16 bytesSpace losses: 0 bytes internal + 4 bytes external = 4 bytes totalHashCode: 694f9431java.lang.Object object internals: OFFSET SIZE TYPE DESCRIPTION VALUE 0 4 (object header) ba 1d 08 2b (10111010 00011101 00001000 00101011) (721952186) 4 4 (object header) 00 00 00 00 (00000000 00000000 00000000 00000000) (0) 8 4 (object header) e5 01 00 f8 (11100101 00000001 00000000 11111000) (-134217243) 12 4 (loss due to the next object alignment)Instance size: 16 bytesSpace losses: 0 bytes internal + 4 bytes external = 4 bytes total 根据上面结果可见： 偏向锁加锁前，计算hashcode，锁标志位不变，仍为 0 1，偏向锁位由 1变为 0，从偏向锁变为了普通对象，且mark word中确实存储了hashcode值。加锁后，锁标志位变为 0 0，即自旋锁。 偏向锁加锁后，计算harshcode，锁标志位变为 1 0，膨胀成重量级锁。 源码实现java代码123456789101112public class T01_Synchronized &#123; static int i = 0; public static void main(String[] args) &#123; Object lock = new Object(); synchronized (lock) &#123; i++; &#125; &#125;&#125; 字节码通过jclasslib可以看到main函数的字节码如下（jclasslib的使用可移步《class文件格式-插件jclasslib》）： 123456789101112131415161718192021new #2 &lt;java/lang/Object&gt;dupinvokespecial #1 &lt;java/lang/Object.&lt;init&gt;&gt;astore_1aload_1dupastore_2monitorentergetstatic #3 &lt;S01_Synchronized/T01_Synchronized.i&gt;iconst_1iaddputstatic #3 &lt;S01_Synchronized/T01_Synchronized.i&gt;aload_2monitorexitgoto 30 (+8)astore_3aload_2monitorexitaload_3athrowreturn 可以看到 synchronized 锁住的同步代码段前后分别插入了一条monitorenter和monitorexit指令。 可以注意到monitorexit指令有两条，这是因为如果在同步代码段发生了异常，会自动释放锁。 JVM实现Lock Record数据结构在hotspot源码（版本：hotspot-37240c1019fd）中，我们首先来看一下Lock Record的数据结构： src\share\vm\runtime\basicLock.hpp中： 1234567891011121314151617181920212223242526272829303132333435363738class BasicObjectLock VALUE_OBJ_CLASS_SPEC &#123; friend class VMStructs; private: BasicLock _lock; // the lock, must be double word aligned oop _obj; // object holds the lock; public: // Manipulation oop obj() const &#123; return _obj; &#125; void set_obj(oop obj) &#123; _obj = obj; &#125; BasicLock* lock() &#123; return &amp;_lock; &#125; // Note: Use frame::interpreter_frame_monitor_size() for the size of BasicObjectLocks // in interpreter activation frames since it includes machine-specific padding. static int size() &#123; return sizeof(BasicObjectLock)/wordSize; &#125; // GC support void oops_do(OopClosure* f) &#123; f-&gt;do_oop(&amp;_obj); &#125; static int obj_offset_in_bytes() &#123; return offset_of(BasicObjectLock, _obj); &#125; static int lock_offset_in_bytes() &#123; return offset_of(BasicObjectLock, _lock); &#125;&#125;;class BasicLock VALUE_OBJ_CLASS_SPEC &#123; friend class VMStructs; private: volatile markOop _displaced_header; public: markOop displaced_header() const &#123; return _displaced_header; &#125; void set_displaced_header(markOop header) &#123; _displaced_header = header; &#125; void print_on(outputStream* st) const; // move a basic lock (used during deoptimization void move_to(oop obj, BasicLock* dest); static int displaced_header_offset_in_bytes() &#123; return offset_of(BasicLock, _displaced_header); &#125;&#125;; 可以看到 BasicObjectLock 中包含了 加锁对象_obj 和 Lock Record _lock，_lock中则包含了mark word的备份_displaced_head。 再往下我们就能看到，BasicLock *就是自旋锁加锁时，实际存入mark word中的指针。 偏向锁偏向锁的加锁过程就是MacroAssembler::biased_locking_enter函数，每个硬件平台有其各自的实现，如x86平台的实现在src\cpu\x86\vm\macroAssembler_x86.cpp文件中。 自旋锁自旋锁的加锁过程为ObjectSynchronizer::slow_enter，在src\share\vm\runtime\synchronizer.cpp中： 123456789101112131415161718192021222324252627282930313233343536void ObjectSynchronizer::slow_enter(Handle obj, BasicLock* lock, TRAPS) &#123; markOop mark = obj-&gt;mark(); assert(!mark-&gt;has_bias_pattern(), "should not see bias pattern here"); if (mark-&gt;is_neutral()) &#123; // Anticipate successful CAS -- the ST of the displaced mark must // be visible &lt;= the ST performed by the CAS. lock-&gt;set_displaced_header(mark); if (mark == (markOop) Atomic::cmpxchg_ptr(lock, obj()-&gt;mark_addr(), mark)) &#123; TEVENT (slow_enter: release stacklock) ; return ; &#125; // Fall through to inflate() ... &#125; else if (mark-&gt;has_locker() &amp;&amp; THREAD-&gt;is_lock_owned((address)mark-&gt;locker())) &#123; assert(lock != mark-&gt;locker(), "must not re-lock the same lock"); assert(lock != (BasicLock*)obj-&gt;mark(), "don't relock with same BasicLock"); lock-&gt;set_displaced_header(NULL); return; &#125;#if 0 // The following optimization isn't particularly useful. if (mark-&gt;has_monitor() &amp;&amp; mark-&gt;monitor()-&gt;is_entered(THREAD)) &#123; lock-&gt;set_displaced_header (NULL) ; return ; &#125;#endif // The object header will never be displaced to this lock, // so it does not matter what the value is, except that it // must be non-zero to avoid looking like a re-entrant lock, // and must not look locked either. lock-&gt;set_displaced_header(markOopDesc::unused_mark()); ObjectSynchronizer::inflate(THREAD, obj())-&gt;enter(THREAD);&#125; 可以看到，加锁流程为： 判断mark word，如果是普通对象，先将mark word存入lock record的displaced_header中，再通过cas操作将lock record的地址存入mark word中，如果成功，则加锁成功，如果失败，就膨胀为重量级锁。 如果判断mark word已经是自旋锁，那么通过is_lock_owned判断mark word中的lock record地址是否在本线程的栈中，如果在，则可重入，加锁成功；如果不在，膨胀为重量级锁。 从源码来看，似乎并未看到很多文章中描述的竞争加剧的条件，而是一旦自旋锁加锁失败，直接膨胀为重量级锁。]]></content>
      <categories>
        <category>多线程</category>
      </categories>
      <tags>
        <tag>多线程</tag>
        <tag>synchronized</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[多线程-JMM]]></title>
    <url>%2F2021%2F01%2F02%2F%E5%A4%9A%E7%BA%BF%E7%A8%8B-JMM%2F</url>
    <content type="text"><![CDATA[前言在多线程编程之中，通常我们最常需要考虑的是两个问题：1. 竞争问题；2. 协调问题。 竞争问题是指多个线程对同一个资源的竞争，比如：需要修改同一个变量、写同一个文件或者修改数据库的同一条记录…… 对于竞争问题，我们通常通过锁机制来保证同一个资源每次只能被一个线程访问。 至于协调问题，一般又分为两种：1. 协调多个线程执行的操作的顺序；2. 多个线程间信息的传递 事实上，问题1往往也是通过问题2来解决的，比如： 一个线程继续向下执行的条件是判断某个变量是否为 true 而另一个线程中，将该变量的值设为 true 实际上，就是一个线程通过共享变量，向另一个线程传递了信息，从而控制了其执行的行为 因此，协调问题，最终又可归结为多线程间信息的传递。 Java中，多线程间的信息传递是靠共享变量实现的。而 JMM（Java Memory Model / java内存模型） 可以说是Java提供的一系列准则和规范，旨在帮助程序猿们准确、高效地解决多线程编程中的协调问题（在JMM中称之为同步问题 Synchronzation）。 我们在很多文章、很多地方听到的许多很难望文生义的名词（诸如：顺序一致性、happens-before原则、内存可见性、MESI等），都来自于JMM。甚至于JMM本身，从其字面意义就很难理解这到底是个什么玩意儿。 JMM究竟是什么？我们现在说的JMM一般指从JDK5开始使用的新内存模型，详细描述可以查阅JSR-133（注：JSR - Java Specification Requests/ Java 规范提案） Oracle官方文档《Java Language Specification》第17章 Threads and Locks，第4小节 Memory Model 中也有收录。 其开头就有这么一段话： The memory model describes possible behaviors of a program. An implementation is free to produce any code it likes, as long as all resulting executions of a program produce a result that can be predicted by the memory model. 大概意思是：JMM可以描述一段程序可能的行为。多线程编程中，如果我们按照JMM的规则写程序，即我们写的程序可以由JMM规则预测出确定的结果，那么我们就可以放飞自我、为所欲为了（不用担心产生无法预期的bug）。 不由让我想到了一句话：We are free, in the cage. 只要咱按照JMM给的规矩写程序，咱就是自由的。 同时，我又想吐槽了，一个指导我们怎么program的规则，干嘛叫Memory Model，为啥不叫Program Model？ 为何需要JMM？为何需要JMM，实际上等价于：为什么多线程编程很容易出bug？为什么不按照JMM编程，就容易产生预期之外的结果？ 还是举前言里面的例子，就这么简单的逻辑，能出啥错？ 还就真能出错，虽然一个线程将共享变量的值设为了true，但另一个线程可能要等1分钟、10分钟甚至更久才能察觉到这个共享变量的值变为了true，这显然并非我们预期的结果。 为啥会出错？ 因为cpu最终执行的指令并非我们原本写的程序，这其中经过了编译器的优化重排序、cpu的指令重排序以及cpu缓存导致的内存重排序，这些各式各样的优化目的是让程序运行的更快，更有效率，但是却可能导致多线程的程序执行结果无法预期。 可能我们还有个问题，JMM只和多线程编程有关？如果只用一个线程，就不需要关心JMM了吗？ 答案是肯定的，单线程不需要考虑JMM。原因在于，上面所说的导致程序运行结果无法预期的各种重排序优化，都必须要遵循 as-if-serial 语义，即无论怎么重排序，单线程程序的执行结果不能被改变。 JMM如何指导我们进行多线程编程？JMM对本地内存的抽象首先我们需要明确几个定义： 共享变量（Shared Variables）：JMM将所有存储在堆内存中的变量（包含了对象实例、静态变量和数组元素）称之为共享变量。因为这些变量存储在堆中，所以被所有线程共享，也是线程间消息传递的媒介。 本地内存（Local Memory）：本地内存是JMM抽象出的一个概念，并不是真实存在的，也就是说无论我们去查JVM的运行时数据区、Object内存布局还是其他什么，都找不到本地内存这么一个东西。这是JMM为了向程序员屏蔽JVM下层的各种优化，而虚拟出来的一个概念。 也就是说，在理解多线程的程序如何运行时，我们不用去管编译器、操作系统、处理器这些底层优化机制，我们只需要想象，共享变量是存储在主存中对所线程共享的，而每个线程都有一个独享的本地内存，本地内存中缓存着共享变量的副本。 如下图所示： 可见，各个线程无法直接读写主存中的共享变量，只能接触到各自本地内存中缓存着的共享变量的副本。至于缓存何时将共享变量改变了的值写回主存中去，缓存何时从主存中读取共享变量最新的值，这就由JMM来规定了。 了解了JMM对本地内存的抽象，我们再来思考一下前言中的例子。 一个线程以为自己将共享变量的值修改为了true，但实际上修改的只是自己本地内存里的副本。 而另一个线程一直在轮询的也不是真正的共享变量的值，而是自己本地内存里副本的值。 因此，前一个线程的共享变量副本写回主存的时机，以及后一个线程共享变量副本从主存中读取最新值的时机，都影响着程序运行的实际行为。 换一种说法，就是前一个线程对共享变量的操作结果对另一个线程来说不可见。 happens-before规则JMM的核心就是happens-before规则。 happens-before是什么？ 如果我们说 操作A happens-before 操作B，那么其含义是：操作A的结果对操作B可见。 注：happens-before直译过来是“发生在….之前”，但实际上，仅对于消息传递而言，我们并不是特别关注操作A是不是真的在操作B之前执行，我们关心的是操作B要能立刻看到操作A执行的结果。 那么有哪些happens-before规则呢？ 一个线程中的每个操作 happens-before 该线程中的任意后续操作。 对monitor锁的解锁操作 happens-before 任意后续对该锁的加锁操作。 对 volatile 变量的写操作 happens-before 任意后续对该变量的读操作。 如果 A happens-before B，B happens-before C，则可以推导出 A happens-before C。 一个线程中的任意操作 happens-before 从该线程的 join() 方法返回。 调用一个线程的 start() 方法 happens-before 该线程中的任意操作。 一个对象的默认值初始化 happens-before 任何后续操作。(注：这里是默认值初始化，而不是构造函数的初始化，也就是说，一个对象new出来之后，可能不一定能立刻读到构造函数中对各个字段的赋值，但至少能读到默认值0、null或false，而不会读到内存中的随机值。) 和程序员密切相关的一般是前4条happens-before规则。 使用happens-before规则还是举前言中的例子，如何使用 happens-before 规则改进程序呢？ 显然第1个规则不适用，因为对共享变量的读和写是在两个线程中的。 第2个似乎可以，在读和写共享变量前后分别加上加锁和解锁操作，于是 加锁 - 修改共享变量 - 解锁 happens-before 加锁 - 读共享变量 - 解锁，这样一个线程就能立刻读到另一个线程修改的结果了。 第3个似乎也可以，对共享变量增加 volatile 关键字，于是 写volatile变量 happens-before 读volatile变量，应该也可以达到我们预期的结果。 坐而论道不若起而行，我们不妨试试。 1234567891011121314151617181920212223242526public class T01_happensBefore &#123; static Boolean flag = false; public static void main(String[] args) &#123; System.out.println("main start"); new Thread(() -&gt; &#123; try &#123; Thread.sleep(2000); flag = true; System.out.println("T1 Set flag true!"); &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; &#125;).start(); while (true) &#123; if (flag) &#123; System.out.println("got flag..."); break; &#125; &#125; &#125;&#125; 上面的代码中，主线程启动了另一个线程，之后就一直检查flag，另一个线程会在2秒后将flag设置为true。 执行结果： 12main startT1 Set flag true! 却迟迟看不到主线程检查到的flag的变化。 我们试试volatile，只需要在flag的声明处加上volatile关键字。 1static volatile Boolean flag = false; 执行结果： 123main startT1 Set flag true!got flag... 使用synchronized在flag读写处加锁也是可以达到预期结果的，这里就不再赘述。 volatile从happens-before规则中我们可以看到，volatile是多线程间协调的重要工具，我们来重点看看volatile的特性。 123456789101112131415public class T02_volatile &#123; int a = 0; volatile boolean flg = false; void write() &#123; a = 1; // 1 flg = true; // 2 &#125; void read() &#123; if (flg) &#123; // 3 int i = a; // 4 &#125; &#125;&#125; 上面的代码中，我们假设线程A中先执行write()方法，之后线程B中执行read() 方法。 按照happens-before规则： 根据规则1：1 happens-before 2，3 happens-before 4 根据规则3 volatile规则：2 happens-before 3 根据规则4 传递性：1 happens-before 4 于是我们发现：一个线程在对 volatile 变量写之前，对其他共享变量的操作，对于另一个线程读 同一个volatile 变量之后，都是可见的。 如果我们以JMM对本地内存的抽象来理解，可以认为： 对一个 volatile 变量写时， JMM 会把该线程本地内存中对应的共享变量副本值写回到主存中去。 对一个 volatile 变量读时， JMM 会把该线程本地内存中对应的共享变量缓冲置为无效，接下来对共享变量的读取会先从主存中读取到最新值。 所以，线程A写一个 volatile 变量，随后线程B读这个 volatile 变量，这个过程实质上是线程A通过主存向线程B发送消息（消息是共享变量（不限于volatile变量）的修改）。]]></content>
      <categories>
        <category>多线程</category>
      </categories>
      <tags>
        <tag>多线程</tag>
        <tag>JMM</tag>
        <tag>内存可见性</tag>
        <tag>happens-before</tag>
        <tag>volatile</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[多线程-基础]]></title>
    <url>%2F2021%2F01%2F01%2F%E5%A4%9A%E7%BA%BF%E7%A8%8B-%E5%9F%BA%E7%A1%80%2F</url>
    <content type="text"><![CDATA[前言 进程、线程、协程/纤程 线程的创建 Thread的常用方法 线程状态机 synchronized、volatile 进程、线程与纤程/协程 进程：资源分配的最小单位，各进程之间的内存空间是相互隔离的，由处理器的MMU映射到物理内存上。 线程：程序执行的最小单位，同一个进程内的各个线程是处于同一个内存空间的。 纤程(fiber)/协程(coroutine)：比线程更轻量级，最著名的是go语言中的纤程。java12之前并没有官方提供纤程支持，有个叫Quasar的纤程库。 线程线程的创建继承Thread类，重写run方法123456class MyThread extand Thread &#123; @Override public void run() &#123; ... &#125;&#125; 1new MyThread().start(); 实现Runnable接口123456class MyRun implement Runnable &#123; @Override public void run() &#123; ... &#125;&#125; 1new Thread(new MyRun()).start(); lamda表达式1new Thread(() -&gt; &#123;...&#125;).start(); 线程池1Executors.newCachedThreadPool(); 线程状态机如下所所示： Thread的常用方法 sleep，线程进入TimedWating状态 yield，线程仍处于Runnable状态，只是被挂起，可能很快被再次调度运行 join，等待其他线程执行完成 synchronized用法修饰代码块123synchronized (obj) &#123; ...&#125; 作用范围：{}内的代码 锁：obj对象，注意obj不可为null，否则会抛NullPointerException obj常用this，这样锁就是调用此代码块的对象 修饰方法123public synchronized void fun() &#123; ...&#125; 作用对象：整个函数 锁：this 等效于： 12345public void fun() &#123; synchronized (this) &#123; ... &#125;&#125; 修饰静态方法123public synchronized static void fun() &#123; ...&#125; 作用范围：整个函数 锁：此class对象 即这个类的所有对象，访问这个方法都是互斥的 特性 synchronized既可以保证原子性，又可以保证可见性 可重入 如果在同步代码段抛出异常，会自动释放锁，如果不希望释放，需要catch处理。 synchronized(obj)，obj不可为String常量，不可为int、long等基础数据类型。 底层实现 JDK早期（JDK1.5之前），锁需要向操作系统申请，重量级锁，效率低。 JDK1.6开始，synchronized实现了锁升级机制： 偏向锁 -&gt; 自旋锁 -&gt; 重量级锁 HotSpot的JVM实现中，锁升级后就不会再降级 自旋锁自旋等待时会消耗CPU资源，重量级锁的申请和线程切换需要较大开销，各有利弊。 底层细节详情请移步：《多线程-synchronized底层实现》 volatile原理可移步《多线程-JMM》 保证可见性举例：如果下面代码中去掉volatile，会导致flag的修改不可见。 1234567891011121314151617181920212223242526public class T01_happensBefore &#123; static volatile Boolean flag = false; public static void main(String[] args) &#123; System.out.println("main start"); new Thread(() -&gt; &#123; try &#123; Thread.sleep(2000); flag = true; System.out.println("T1 Set flag true!"); &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; &#125;).start(); while (true) &#123; if (flag) &#123; System.out.println("got flag..."); break; &#125; &#125; &#125;&#125; 禁止指令重排序著名的DCL(Double Check Lock)单例实现中，如果去掉volatile，可能导致单例的赋值和初始化重排序，导致拿到尚未初始化完成的对象。 1234567891011121314public class Singleton()&#123; private volatile static Singleton singleton; private Sington()&#123;&#125;; public static Singleton getInstance()&#123; if(singleton == null)&#123; synchronized (Singleton.class)&#123; if(singleton == null)&#123; singleton = new Singleton(); &#125; &#125; &#125; return singleton; &#125; &#125;]]></content>
      <tags>
        <tag>多线程</tag>
        <tag>volatile</tag>
        <tag>synchronized</tag>
        <tag>Thread</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Redis-哨兵(Sentinel)]]></title>
    <url>%2F2020%2F11%2F09%2FRedis-%E5%93%A8%E5%85%B5-Sentinel%2F</url>
    <content type="text"><![CDATA[前言Redis 哨兵（Sentinel）的官方文档： Redis Sentinel Documentation 简而言之，哨兵机制是Redis高可用性的保障。 本文主要对该官方文档进行了翻译，同时也结合源码做了部分注解。 概述Redis Sentinel为Redis提供高可用性。通过Sentinel可以部署一套无需人工干预，即可抵抗某些故障的高可用Redis。 Redis Sentinel还提供了一些附加任务，如监视，通知，给客户端（client）提供配置信息等。 Sentinel的完整功能列表（big picture）： 监控。Sentinel会不断检查Redis的Master实例和Slave实例是否按预期工作。 通知。Sentinel可以通过API通知系统管理员或其他计算机程序，其中一个受监视的Redis实例出了问题。 自动故障转移。如果Master未按预期工作，则Sentinel可以启动故障转移过程，在该过程中将某个Slave升级为Master，将其他Slave的主从复制(Replication)目标修改为新的Master，并通知使用Redis应用程序要使用的新地址。 配置提供者。Sentinel为客户端client提供服务发现功能：client连接到Sentinels，询问当前Redis Master实例的地址。如果发生故障转移，Sentinels将报告新地址。 Sentinel的分布式性质Redis Sentinel是一个分布式系统： Sentinel本身设计为在有多个Sentinel进程协同合作的配置中运行。具有多个Sentinel进程进行协作的优点如下： 降低误报的几率：当多个Sentinel就给定的主机不再可用达成共识时，才执行故障转移。 避免单点故障：故障转移系统本身也可能出现单点故障，多个Sentinel进程协同运行，保证了即使不是所有的Sentinel进程都在工作，Sentinel仍能正常工作，从而使系统能够应对故障。 Sentinels，Redis实例（Master和Slave）以及连接到Sentinel和Redis的客户端的总和也是具有特定属性的大型分布式系统。在本文档中，将逐步介绍各个概念，先介绍基本信息，以便理解Sentinel的基本特性，再介绍Sentinel的工作原理（可选读）。 Quici Start获取SentinelSentinel的当前版本为Sentinel 2。它对Sentinel初版实现进行了重构，使用了更强大且更易于预测的算法（会在本文档中进行说明）。 自Redis 2.8之后的版本中，都已包含稳定版本的Redis Sentinel。 Redis Sentinel的不稳定分支中进行着迭代开发，一旦新功能稳定，便会立即合并回最新的稳定分支。 Redis 2.6随附的Redis Sentinel版本1已被弃用，不应使用。 运行Sentinel有两种方法启动Sentinel： 使用 redis-sentinel（实际上是一个名为redis-sentinel，指向redis-server的软连接）： 1redis-sentinel /path/to/sentinel.conf 直接使用redis-server以Sentinel模式启动： 1redis-server /path/to/sentinel.conf --sentinel 两种方法是等效的。 但是，在运行Sentinel时必须使用配置文件，因为系统将使用此文件来保存当前状态，以便在重启时重新加载。如果未提供配置文件或配置文件路径不可写，Sentinel会拒绝启动。 Sentinels默认情况下会监听TCP端口26379的连接，因此，要使Sentinels正常工作，必须打开服务器的端口26379，以接收来自其他Sentinel实例的连接。否则，Sentinels无法讨论也不能就该做什么达成共识，因此将永远不会执行故障转移。 译者注： 从源码 server.c 里可以看到，判断是否以哨兵模式启动的条件： 12345678910/* Returns 1 if there is --sentinel among the arguments or if * argv[0] contains "redis-sentinel". */int checkForSentinelMode(int argc, char **argv) &#123; int j; if (strstr(argv[0],"redis-sentinel") != NULL) return 1; for (j = 1; j &lt; argc; j++) if (!strcmp(argv[j],"--sentinel")) return 1; return 0;&#125; 如果执行的文件名包含”redis-sentinel”，或者执行参数中有”–sentinel”，就以哨兵模式启动。 部署前有关Sentinel的基本知识 一个健壮的部署至少需要三个Sentinel实例。 应将三个Sentinel实例放置到独立计算机或虚拟机中（不会同时发生故障），例如在不同的可用区域上执行的不同物理服务器或虚拟机。 由于Redis使用异步复制，因此Sentinel + Redis分布式系统不能保证在故障期间保留已确认的写入。但是，部署Sentinel时可以采取一些方法，使得数据写入丢失窗口仅限于某些时刻。还有其他一些不太安全的方法来部署它。 客户端需要Sentinel支持。并非所有的流行客户端库都具有Sentinel支持。 如果您不在开发环境中不时进行测试，则没有安全的HA设置，如果可以，则在生产环境中甚至可以更好地进行测试。您可能有一个错误的配置，只有在为时已晚时（主服务器停止工作的凌晨3点），该错误才会变得明显。 Sentinel，Docker或其他形式的网络地址转换或端口映射应格外小心：Docker执行端口重新映射，会破坏Sentinel对其他Sentinel进程的自动发现以及主副本的列表。有关更多信息，请参阅本文档后面有关Sentinel和Docker的部分。 配置前哨Redis源码目录内包含一个名为sentinel.conf的文件 ，该文件是一个示例配置文件，可用于配置Sentinel。如下所示的是典型的最小配置文件： 123456789sentinel monitor mymaster 127.0.0.1 6379 2sentinel down-after-milliseconds mymaster 60000sentinel failover-timeout mymaster 180000sentinel parallel-syncs mymaster 1sentinel monitor resque 192.168.1.3 6380 4sentinel down-after-milliseconds resque 10000sentinel failover-timeout resque 180000sentinel parallel-syncs resque 5 上面的示例中监视了两组Redis实例，每个实例由一个master和未定义数量的slave组成。一组实例名为mymaster，另一组名为resque。 配置中只需要指定要监视的master，无需指定slave，slave是自动发现的。Sentinel会将slave的其他信息自动更新进配置文件中（以便在重新启动时保留该信息）。当在故障转移期间将slave提升为master时，以及每次发现新的Sentinel时，都会重写配置。 配置需要监控的Mastersentinel monitor语句参数的含义如下： 1sentinel monitor &lt;master-group-name&gt; &lt;ip&gt; &lt;port&gt; &lt;quorum&gt; 各配置选项的含义： 第一行用于告诉Redis监视一个名为 mymaster 的master，其地址为127.0.0.1，端口为6379，仲裁数为2。其中 quorum 表示仲裁数，其意义为： 当判定master不可用的Sentinel进程数量 ≥ quorum时，才能真正标记master不可用，并最终开始故障转移过程。 但是，quorum仅用于检测故障。为了实际执行故障转移，需要将其中一名Sentinels选为故障转移的负责人，并授权其进行操作。必须有超过半数的Sentinel进程投票，才会进行故障转移。 例如，有5个Sentinel进程，并且给定主服务器的仲裁设置为2，则将发生以下情况： 如果有两个Sentinel同时认为master不可访问，则这两个Sentinel中的一个将尝试启动故障转移。 如果总共至少有三个Sentinel可以访问，则故障转移将被授权并实际上开始。 这意味着在发生故障期间，如果超过半数的Sentinel进程无法进行对话，Sentinel不会启动故障转移（即：不过半数无故障转移）。 其他配置项其他配置项几乎总是采用以下形式： 1sentinel &lt;option_name&gt; &lt;master_name&gt; &lt;option_value&gt; 配置项： down-after-milliseconds 不可用时间，以毫秒为单位。是指Sentinel无法访问某实例（实例未答复PING或答复错误），持续所指定的时间后，认为实例不可用。 parallel-syncs配置了在故障转移时，同时和新master的同步数据的slave数量。数字越小，完成故障转移过程所花费的时间越多；但越大就意味着越多的slave因为复制而不可用（尽管slave在复制过程中绝大部分时间是非阻塞的，但仍会在载入大量数据时对外停止服务一小段时间）。将此选项设置为值1，可以确保一次只有一个副本无法访问。 其他选项在本文档的其余部分中进行了描述，并在sentinel.confRedis分发随附的示例文件中进行了说明。 使用SENTINEL SET命令，可以在运行时修改所有配置参数。有关更多信息，请参见“在运行时重新配置Sentinel”部分。]]></content>
      <categories>
        <category>Redis</category>
      </categories>
      <tags>
        <tag>Redis</tag>
        <tag>Sentinel</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Redis-主从复制]]></title>
    <url>%2F2020%2F11%2F07%2FRedis-%E4%B8%BB%E4%BB%8E%E5%A4%8D%E5%88%B6%2F</url>
    <content type="text"><![CDATA[前言Redis提供的Replication（复制）特性，能够通过很简单的配置，实现Redis服务器的主从复制功能。 不过，通常不会只单独使用Replication，而是会搭配Sentinel（哨兵）实现主备高可用或者搭配Cluster（集群）实现数据分片的高可用集群。 本文仅介绍Replication相关配置和特性。 使用Replication主要用于解决两个问题： 提高并发响应能力 一个master处理写请求，多个slave分摊读请求的压力。 高可用 如果master挂了，将一个slave选举为新的master，实现故障转移。需要配合Sentinel（哨兵）实现。 开启主从复制非常简单： 在slave的配置文件redis.conf中配置master的ip、端口号和密码即可： 12replicaof &lt;masterip&gt; &lt;masterport&gt;masterauth &lt;master-password&gt; 可以通过INFO replication 命令查看相关信息： 12345678910111213141510.0.0.230:6379&gt; INFO REPLICATION# Replicationrole:masterconnected_slaves:2min_slaves_good_slaves:2slave0:ip=10.0.0.231,port=6379,state=online,offset=176937336,lag=0slave1:ip=10.0.0.232,port=6379,state=online,offset=176937336,lag=0master_replid:adf9fadb5ba7a148688a5631adec21d2b4f8428bmaster_replid2:91f914d3b46c3792e6a94b12fa5c55437bcce69fmaster_repl_offset:176937620second_repl_offset:338068repl_backlog_active:1repl_backlog_size:1048576repl_backlog_first_byte_offset:175889045repl_backlog_histlen:1048576 Replication常用配置项： replica-serve-stale-data yes 配置为yes，则slave在同步过程中，也会响应客户端请求，配置为no，则在同步完之前会回复SYNC with master in progress replica-read-only yes slave通常配置为只读模式 repl-diskless-sync no 若开启，则同步时，master不会先将rdb文件保存到磁盘再传输，而是直接通过网络传输。磁盘性能低但网络带宽大的情况下可以开启。 min-replicas-to-write 3 如果master连接的slave数量小于3，则master不再接受写请求。这是为了防止出现网络分区后，master和一部分clients被分隔出来，其余的redis实例已经选举产生了新的master并对外服务，如果原master仍然继续可写，那么这些写请求在网络恢复后，实际上就相当于丢失了。 min-replicas-max-lag 10 如果距离上一次接收到slave的ping的时间超过10秒，即认为该slave不可用。 实现原理Redis通过重同步（resync）和命令传播（command propagate）来实现不同场景下的数据同步。 重同步重同步用于将 slave 的数据库状态更新至 master 当前所处的数据库状态。重同步又分为完整重同步和部分重同步。 重同步使用SYNC（2.8版本后已被PSYNC取代）或PSYNC命令实现。 PSYNC可实现完整重同步（PSYNC ? -1）或部分重同步（PSYNC &lt;replication-id&gt; &lt;offset&gt;) SYNC只能实现完整重同步 通常初次复制使用完整重同步；断线重连后使用部分重同步 完整重同步 如上图所示，完整重同步流程如下： slave 通过 SYNC或 PSYNC 命令，向 master 发起同步请求。 master 返回 FULLRESYNC 告知 slave 将执行 完整重同步，判定条件为： 请求命令是 完整重同步SYNC。 请求命令是 完整重同步PSYNC ? -1。 请求命令是 部分重同步PSYNC &lt;replication-id&gt; &lt;offset&gt;，但是 &lt;replication-id&gt; 不是 master 的 replication-id，或者 slave 给的 &lt;offset&gt; 不在 master 的 复制积压缓冲区 backlog 里面。 master 执行 BGSAVE 命令，将当前数据库状态保存为 RDB 文件。 生成 RDB 文件完毕后，master 将该文件发送给 slave。 slave 收到 RDB 文件后，将其加载至内存。 master 将 backlog 中缓冲的命令发送给 slave（一开始在 BGSAVE 时记录了当时的 offset）。 slave 收到后，逐个执行这些命令。 部分重同步 如上图所示，部分重同步流程如下： slave 通过 PSYNC &lt;replication-id&gt; &lt;offset&gt; 命令，向 master 发起 部分重同步 请求。 master 返回 CONTINUE 告知 slave 同意执行 部分重同步，先决条件为： &lt;replication-id&gt; 是 master 的 replication-id，并且 slave 给的 &lt;offset&gt; 在 master 的 复制积压缓冲区backlog 里面 master 将 backlog 中缓冲的命令发送给 slave（根据 slave 给的 offset）。 slave 收到后，逐个执行这些命令。 命令传播命令传播 用于在 master 的数据库状态被修改时，将导致变更的命令传播给 slave，从而让 slave 的数据库状态与 master 保持一致。 master 进行命令传播时，除了将写命令直接发送给所有 slave，还会将这些命令写入 复制积压缓冲区 ，用于后续可能发生的 部分重同步 操作。 复制积压缓冲区 backlog复制积压缓冲区 是 master 维护的一个固定长度（fixed-sized）的先进先出（FIFO）的内存队列： 队列的大小由配置 repl-backlog-size 决定，默认为 1MB。当队列长度超过 repl-backlog-size 时，最先入队的元素会被弹出，用于腾出空间给新入队的元素。 队列的生存时间由配置 repl-backlog-ttl 决定，默认为 3600 秒。如果 master 不再有与之相连接的 slave，并且该状态持续时间超过了 repl-backlog-ttl，master 就会释放该队列，等到有需要（下次又有 slave 连接进来）的时候再创建。 master 会将最近接收到的写命令保存到 复制积压缓冲区，其中每个字节都会对应记录一个偏移量 offset。 与此同时，slave 会维护一个 offset 值，每次从 master 传播过来的命令，一旦成功执行就会更新该 offset。尝试 部分重同步 的时候，slave 都会带上自己的 offset，master 再判断 offset 偏移量之后的数据是否存在于自己的 复制积压缓冲区 中，以此来决定执行 部分重同步 还是 完整重同步。 弱一致性默认情况下，Redis使用异步的方式同步数据，即：master不会等待确认slave是否已经同步完成之后，才回复客户端写命令的执行结果。 Redis甚至无法保证最终一致性（最终一致性通常需要消息队列来实现），某些情况下（如故障转移期间），已经确认的写入也是有可能丢失的。 从CAP的角度来说，Redis选择了可用性，而放弃了强一致性。 slave的key过期问题我们知道对于master的过期key的清理有两种方式： 主动判定：周期性随机轮询若干个key，若过期，则清除 被动判定：访问某个key时，先判定该key是否过期，若过期，则清除 然而，slave不会主动清除过期的key，只有master判定某个key过期后，主动生成DEL删除命令发送给slave，slave才会清除该key。 这种机制导致了如果master中过期的key没有及时清除，那么从slave中是能够读出的。 从搜索到的很多文章中指出，3.2版本后该问题得到了修复，而Redis官方的Replication文档中指出：对于读取操作，slave会根据自身的逻辑时钟来避免返回一个过期的key。说的比较模棱两可，参考文献[3]中从源码、git的提交记录、实验等多个角度对此问题展开了分析，最终结论是： 所谓的逻辑时钟就是系统本地时钟，主从之间并没有针对时钟做同步或相关处理 对于expire命令，指定key存活一段时间后过期。即使主从时间不一致，但度过的时长是基本一样的，因此结果通常没有问题。 对于expireat命令，指定了key过期的时间戳，这种情况，如果主从时间不一致，客户端在同一时刻访问主从节点的同一个key，得到的TTL是不同的。 因此，建议： 运行Redis的机器需要做好对时 尽可能使用expire而非expireat 参考文献： [1] Redis官方文档 - replication [2] 《Redis设计与实现》 [3] 《redis循环键_关于Redis主从节点数据过期性的思考，它真的足够一致了吗？》]]></content>
      <categories>
        <category>Redis</category>
      </categories>
      <tags>
        <tag>Redis</tag>
        <tag>replication</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Redis-持久化]]></title>
    <url>%2F2020%2F11%2F02%2FRedis-%E6%8C%81%E4%B9%85%E5%8C%96%2F</url>
    <content type="text"><![CDATA[前言Redis提供了持久化功能，将内存中的数据定期备份或通过命令导出到硬盘上，启动时，若检测到备份文件，会首先从备份文件中恢复数据到内存。 redis提供两种持久化方式： 快照：RDB 日志（append only file）：AOF 快照 RDB使用方法 通过命令显式地导出 SAVE：阻塞式，切勿在生产环境使用 BGSAVE：非阻塞式 默认导出到安装目录 可通过CONFIG GET dir命令查看安装目录 在.conf文件中配置规则定期备份 SAVE &lt;seconds> &lt;changes> 含义：在seconds秒内，发生了至少changes次修改，则备份一次 可以配置多条 备份是非阻塞的 默认配置： 123save 900 1save 300 10save 60 10000 含义：满足以下三个条件中的任意一个，BGSAVE命令就会被执行： 服务器在900秒之内，对数据库进行了至少1次修改 服务器在300秒之内，对数据库进行了至少10次修改 服务器在60秒之内，对数据库进行了至少10000次修改 时点性含义：快照的数据就是执行持久化指令时刻的数据，在持久化过程中的数据变化，不会体现到快照中。 实现： 阻塞式：停止对外服务 非阻塞式： redis进程使用fork创建子进程，并将要持久化的数据export给子进程 子进程拿到的数据副本，不会随着父进程的修改而改变 底层机制是操作系统层面的写时复制机制。父子进程的数据开始时是指向同一块内存的，一旦父子进程的任意一方试图修改数据，就会触发写时复制机制，重新创建一份副本，修改值，并将指针指向新的修改后的副本，这样，修改的值不会影响到另一个进程 弊端丢失数据的可能性相对较大，时点与时点之间的数据容易丢失 优点字节流序列化，恢复的速度较快 日志 AOFAOF持久化将redis的写操作记录到文件中。 使用方法.conf文件中配置，开启AOF备份： 1appendonly yes 注：redis配置文件中，若同时开启了rdb和aof，两种备份文件都会生产，但只会以AOF恢复。 优点丢失数据的可能性相对小 弊端时间长了之后，日志体量过大； 恢复相对较慢 解决方案重写日志文件： redis4.0之前：删除抵消的命令，合并重复的命令，最终仍是一个纯指令文件 redis4.0之后：先将旧数据以rdb格式存到aof文件中，再将增量数据以指令的格式追加到aof文件中，最终是快照和日志的混合体，利用了rdb的快和aof的全 详细配置 开启AOF：appendonly yes AOF文件名：appendfilename &quot;appendonly.aof&quot; 写磁盘频率：appendfsync always/everysec/no always：每次写完，都flush到磁盘 everysec：每秒调一次flush，这是默认配置 no：不主动flush，操作系统的写文件缓冲区满了自动写到磁盘，一般缓冲区4k大小 开启rdb和aof混合模式：aof-use-rdb-preamble yes 自动重写触发的条件： auto-aof-rewrite-percentage 100：当aof文件大小是上一次重写时的aof文件大小的200%时，触发重写 auto-aof-rewrite-min-size 64mb：aof文件小于64mb大小时，不会触发重写]]></content>
      <categories>
        <category>Redis</category>
      </categories>
      <tags>
        <tag>Redis</tag>
        <tag>Persistence</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Redis-基础]]></title>
    <url>%2F2020%2F10%2F30%2FRedis-%E5%9F%BA%E7%A1%80%2F</url>
    <content type="text"><![CDATA[前言Redis是一个开源（BSD许可）的，基于内存的数据存储系统，它可以用作数据库、缓存和消息中间件。 安装、启动环境：CentOS 7.6 (1810) 下载最新的稳定版本redis 1wget https://download.redis.io/releases/redis-6.0.9.tar.gz 编译 由于gcc版本较低，直接编译会报错，因此，先更新gcc 123yum -y install centos-release-sclyum -y install devtoolset-9-gccscl enable devtoolset-9 bash 解压编译 12345tar -xzvf redis-6.0.9.tar.gzmv redis-6.0.9 rediscd redismakemake install 测试 1redis-server -v 结果 1Redis server v=6.0.9 sha=00000000:0 malloc=jemalloc-5.1.0 bits=64 build=4b37fcaf3ca1b943 启动redis-server 1redis-server ./redis.conf 其中 ./redis.conf 是配置文件路径，如果不指定配置文件，则使用默认参数启动。 在下载并解压后的文件夹根目录中有配置模板 redis.conf，其中的注释详细的说明了每个参数的意义。 客户端使用redis中自带了一个客户端工具 redis-cli，通过类shell的交互方式与redis server连接、交互。 redis-cli 中对于命令，大小写不敏感，对于变量名，大小写敏感。 启动客户端1reids-cli -h 127.0.0.1 -p 6379 -n 0 其中： -h 和 -p 参数 指定 redis server 的 host 和 端口号，不指定该参数，默认连接127.0.0.1:6379 -n参数指定使用第几个数据库，redis默认有16个库，各库中的数据相互独立。不使用-n参数时，默认使用数据库0 如果redis server配置了密码，还需要使用 -a 参数配置密码 查看帮助redis的help指令提供了对每条指令的帮助信息。 按组查看帮助：help @&lt;group&gt; ，如help @string，会展示所有string相关的指令格式和简介。共分为15个组，可以使用TAB键切换和自动补全。 查看某条指令的帮助： help &lt;cmd&gt; 数据类型redis以key-value键值对的形式存储数据，所有的key都是String类型，value有5钟数据类型，分别是String、List、Set、SortedSet、Hash，每种数据类型都有其支持的操作命令。 字符串 String字符串是最常用的数据类型。 基本操作 命令 意义 SET key val [EX sec &#124; PX ms &#124; KEEPTTL] [NX &#124; XX] 设置字符串内容可选项[EX sec &#124; PX ms &#124; KEEPTTL]：设置过期时间，如果不配置，默认-1，即不过期EX 后面跟的数字表示秒，PX后面跟的数字表示毫秒，KEEPTTL表示保留原有的过期时间如：SET k1 “abc” EX 10，表示10秒后过期可选项[NX &#124; XX]表示命令执行的条件NX：key不存在，才能set成功，即只能新建，XX：key存在，才能set成功，即只能更新 GET key 获取字符串内容 MSET key1 val1 key2 val2 … 设置多个字符串内容 MGET key1 key2 … 获取多个字符串内容 GETSET key value 设置新值并返回旧值 字符串操作 命令 意义 APPEND key val 字符串拼接 GETRANGE key start end 字符串截取，start、end可取正负索引 SETRANGE key offset val 从offset位置开始覆盖 STRLEN key 字符串长度 数值操作 命令 意义 INCR/DECR key 加/减1常用于秒杀、点赞数、评论数等原子操作，避免高并发下的数据库事务操作 INCRBY/DECRBY key val 加/减指定数 INCRBYFLOAT/DECRBYFLOAT key val 加/减小数 注：数值操作需要保证字符串的值能够被解析成十进制数字，否则会报错，如： 1234127.0.0.1:6380&gt; GET k1"2a"127.0.0.1:6380&gt; INCR k1(error) ERR value is not an integer or out of range Bitmap操作 命令 意义 SETBIT key bit val 将第bit为设置成0或1 bitpos key bit [start] [end] 找到bit第一次出现的位置bit只能是0或1start和end是字节索引返回结果是位索引 bitcount key [start end] 计算1的数量 BITOP OP dest key1 key2… 对多个bitmap执行位操作，并将结果存储到dest中OP可取：AND、OR、NOT、XOR 应用场景： 统计用户的登录天数，统计窗口随机 数据结构：key为用户，bit为天数 登录：SETBIT username day 1，如Joy在今年第5天登录，就 SETBIT Joy 5 1 查询登录天数：BITCOUNT username start end，如统计JOY最近7天的登录天数，BITCOUNT Joy -7 -1 活跃统计：统计某段时间内登陆过的用户 数据结构：key为日期，bit用户id 登录：SET date userid 1，如2020.10.1这一天5号用户登录，就SETBIT 20201001 5 1 查询某段时间的活跃用户：1.将这些天的记录取OR或操作，2. BITCOUNT统计登录数 列表 ListList类型常用于实现队列、栈等数据结构。 特性从源码中对list和list节点的定义可以看出： 双向链表 有头尾指针 可以方便的实现正负索引 123456789101112131415161718192021typedef struct quicklistNode &#123; struct quicklistNode *prev; struct quicklistNode *next; unsigned char *zl; unsigned int sz; /* ziplist size in bytes */ unsigned int count : 16; /* count of items in ziplist */ unsigned int encoding : 2; /* RAW==1 or LZF==2 */ unsigned int container : 2; /* NONE==1 or ZIPLIST==2 */ unsigned int recompress : 1; /* was this node previous compressed? */ unsigned int attempted_compress : 1; /* node can't compress; too small */ unsigned int extra : 10; /* more bits to steal for future usage */&#125; quicklistNode;typedef struct quicklist &#123; quicklistNode *head; quicklistNode *tail; unsigned long count; /* total count of all entries in all ziplists */ unsigned long len; /* number of quicklistNodes */ int fill : 16; /* fill factor for individual nodes */ unsigned int compress : 16; /* depth of end nodes not to compress;0=off */&#125; quicklist; 操作 命令 意义 LPUSH/RPUSH key val1 val2 … 从头（左）/尾（右）添加一个或多个元素 LPOP/RPOP key val1 val2 … 从头（左）/尾（右）弹出一个或多个元素 LRANGE key start stop 取list中指定位置的数据start和stop可以取正负索引，0表示第1个元素，-1表示倒数第一个元素如：LRANGE 0 -1表示取所有元素 LINDEX key index 根据索引取元素 LSET key index val 根据元素设置元素值 LREM key count val 从list中删除count个值为val的元素若count为正，从头（左）删除；若count为负，从尾（右）删除 BLPOP/BRPOP key 阻塞的弹出值 LTRIM key start stop 删除start左侧和stop右侧的所有元素例：LTRIM 0 -1 不删任何一元素 实现常用的数据结构 队列：先进先出，使用反向命令，即 lpush + rpop 或 rpush + lpop 栈：后进先出，使用同向命令，即 lpush + lpop 或 rpush + rpop 阻塞的单播队列：blpop + rpush 或 brpop + lpush 集合 Set特性 去重 集合内元素值为String类型 存储顺序与插入顺序无关 基本操作 命令 意义 SADD key val1 val2 … 向集合中添加一个或多个元素 SREM key val1 val2 … 从集合中删除一个或多个元素 SMEMBERS key 获取集合所有元素 SISMEMBER key val 判断是否在集合内 SCARD key 集合内元素数量 集合的交、并、差操作 命令 意义 SINTER key1 key2 … 求多个集合的交集 SINTERSTORE dest key1 key2 … 求多个集合的交集并将结果存储到dest中 SUNION key1 key2 … 求多个集合的并集 SUNIONSTORE dest key1 key2 … 求多个集合的并集并将结果存储到dest中 SDIFF key1 key2 … 求一个集合对其余集合的差集 SDIFFSTORE dest key1 key2 … 求一个集合对其余集合的差集并存储到dest中 随机操作SRANDMEMBER 用法：SRANDMEMBER key count count值可以为正数或负数 若count为正数，随机取出一个去重的结果集，结果集内元素数量不超过原集合内的元素数量 若count为负数，随机取出一个结果集，结果集内的元素可能重复，结果集内元素的数量一定为|count| SPOP 用法：SPOP key [count] count值必须为正数，如果不传，默认为1 每次随机从集合中取出count个元素，并从集合中去除该元素 应用：抽奖 集合中放入所有候选人 多轮抽奖 单个轮次中获奖人一定不同，但一个人可以在多个轮次中奖：每轮抽奖使用 SRANDMEMBER key count，其中count是正数 单个轮次中一个人也可以获多个奖（适用于奖品数大于候选人数的情况）：每轮抽奖用 SRANDMEMBER key count，其中count是负数 单个轮次中获奖人一定不同，且一个人一旦中奖，在后面轮次中就不再参与抽奖：每轮抽奖用 POP key count 有序集合 SortedSet有序集合常用于榜单排序。 特性 去重 集合内元素为String类型 有序，集合内每个元素有float类型的分数score，根据元素的score排序 基本操作 命令 意义 ZADD key score1 member1 score2 member2… 向有序集合中添加一个或多个元素 ZCARD key 获取有序集合的元素数量 ZCOUNT key min max 获取有序集合中指定分数区间内的元素个数 ZINCRBY key increment member 对有序集合内的指定元素的分数增加increment ZRANK key member 返回有序集合中某元素的排名（从小到大，从0开始） ZREM key member1 member2… 删除一个或多个元素 集合的交、并、差操作ZINTERSTORE/ZUNIONSTORE/ZDIFFSTORE dest numKeys key1 key2 … [WEIGHTS w1 w2 …] [AGGREGATE SUM|MIN|MAX] dest：存储操作结果的key numKeys：参与操作的集合数量 WIGHTS w1 w2…：权重，权重的数量需要和numKeys对应，执行操作时，会先将各集合中元素乘以该集合对应的权重。不填默认为1 AGGREGATE：对score的处理方法，不填默认为SUM。可选SUM，MIN，MAX 散列 HashHash适合存储对象，将对象的属性以键值对的形式存储到一个key中，如： 存储一个个人信息对象 {&quot;name&quot;:&quot;Joy&quot;, &quot;age&quot;:21, &quot;height&quot;:165, &quot;weight&quot;:50} 1234567891011127.0.0.1:6380&gt; HMSET person1 name Joy age 21 height 165 weight 50 OK127.0.0.1:6380&gt; HGETALL person11) "name"2) "Joy"3) "age"4) "21"5) "height"6) "165"7) "weight"8) "50" Hash的基本操作命令如下： 命令 意义 HSET key field val 设置哈希表的某个字段 HMSET key field1 val1 field2 val2 … 设置哈希表的多个字段 HGET key field 获取哈希表的某个字段 HMGET key field1 field2 … 获取哈希表的多个字段 HKEYS key 获取哈希表的所有字段名 HVALS key 获取哈希表的所有字段值 HGETALL key 获取哈希表的所有字段名和值 HDEL key field1 field2 … 删除哈希表中的一个或多个字段 HINCRBY/HINCRBYFLOAT key field val 为哈希表的指定字段的整数值/浮点数值增加val redis作为缓存缓存的特点 缓存数据不重要（和数据库相比） 不是全量数据，而是热点数据 会随着访问而变化 问题内存的大小是有限的，需要redis中的数据随着业务访问而变化，只保留热数据。 相关特性 虚拟内存：2.6版本之前有此功能，开启了该功能（vm-enabled ture）后，若使用内存达到vm-max-memory，redis会将访问率不高的冷数据交换到磁盘中去，这些数据被访问时，又会加载到内存中。2.6之后的版本已移除该功能。 key的有效期 设置有效期的方法： SET 命令的 EX、PX、KEEPTTL参数 EXPIRE、PEXPIRE命令：设置过期剩余时间 EXPIREAT、PEXPIREAT命令：设置过期时间戳 读命令不会延长过期时间 写命令，如果不加EX、PX或KEEPTTL参数，会剔除过期时间，即该key不会过期 过期判定机制 被动判定：访问该key时，判断是否过期 主动判定：周期性轮询判定：1. 每10秒判定20个key 2. 清除过期的key 3. 如果过期key占比超过25%，重复第1步 内存有限，淘汰冷数据，在 redis.cnf 中配置相关参数： maxmemory : 最大内存，当redis使用的内存超过改参数指定的内存大小，则按照配置的策略尝试删除key。如果无法删除或淘汰策略配置为了noeviction，则当执行需要增加内存的指令（如SET, LPUSH等）时，会返回错误。 maxmemory-policy ：达到最大内存时的淘汰策略。 noeviction：不淘汰 volatile-lru：对设置了有效期的key采用lru淘汰 allkeys-lru：对所有key采用lru淘汰 volatile-lfu：对设置了有效期的key采用lfu淘汰 allkeys-lfu：对所有key采用lfu淘汰 volatile-random：对设置了有效期的key采用随机淘汰 allkeys-random：对所有key采用随机淘汰 volatile-ttl：淘汰过期剩余时间最少的key maxmemory-samples：采样数量。redis的LRU、LFU和TTL淘汰都是近似的算法，考虑到性能问题，并没有对全量数据采样。该参数默认值是5，表示采样5个key并从中选一个淘汰。redis认为5已经能够达到足够的精度，10已经非常接近精确算法的结果，但会消耗更多的cpu资源。 若没有配置maxmemory，当使用内存达到物理内存上线后，会使用操作系统的虚拟内存机制，会导致redis性能急剧下降。 注： lru - least recently used，最近最少使用，淘汰最长时间未被使用的条目 lfu - least frequently used，最不经常使用，淘汰一段时间内使用次数最少的条目 redis与memcached的对比redis常常被拿来与memcached做比较。 首先看看各自官网对自己的定义： redis（redis.io）：Redis is an open source (BSD licensed), in-memory data structure store, used as a database, cache, and message broker. memcached（memcached.org）：Free &amp; open source, high-performance, distributed memory object caching system 从其各自官网定义可以看出来： 相同点：两者都是开源的（事实上都是BSD开源协议）；两者都是基于内存的； 不同点：memcached只是定位于缓存，而redis除了缓存，还可用于数据库、消息中间件 除此之外： 对比项 redis memcached 性能 核心业务单线程，只能利用一个cpu核，但是省去了锁、上下文切换等方面的开销根据附录redis作者antirez在Stack Overflow上的回答，redis在约100k以上的大数据存取上性能略逊于memcached，但无论使用哪个，基本上都不用担心性能问题成为系统瓶颈。 多线程，主线程listen，多个worker线程 持久化 支持 不支持，一旦重启，数据就丢失 支持的数据类型和操作 支持字符串、列表、集合、有序集合、哈希且操作也非常丰富计算向数据移动的思想 只支持字符串 分布式高可用集群 官方提供Sentinel、主从复制、cluster等机制实现高可用集群 官方本身不支持分布式集群的服务器本身是不通讯的，其实是伪分布式，是靠客户端通过分片算法把数据存到不同的memcached服务器中高可用需要第三方软件（如：repcached，memagent、memcached-ha等）或自己设计实现 附录：antirez在Stack Overflow上的回答https://stackoverflow.com/questions/2873249/is-memcached-a-dinosaur-in-comparison-to-redis You should not care too much about performances. Redis is faster per core with small values, but memcached is able to use multiple cores with a single executable and TCP port without help from the client. Also memcached is faster with big values in the order of 100k. Redis recently improved a lot about big values (unstable branch) but still memcached is faster in this use case. The point here is: nor one or the other will likely going to be your bottleneck for the query-per-second they can deliver. You should care about memory usage. For simple key-value pairs memcached is more memory efficient. If you use Redis hashes, Redis is more memory efficient. Depends on the use case. You should care about persistence and replication, two features only available in Redis. Even if your goal is to build a cache it helps that after an upgrade or a reboot your data are still there. You should care about the kind of operations you need. In Redis there are a lot of complex operations, even just considering the caching use case, you often can do a lot more in a single operation, without requiring data to be processed client side (a lot of I/O is sometimes needed). This operations are often as fast as plain GET and SET. So if you don’t need just GET/SET but more complex things Redis can help a lot (think at timeline caching). 译文参考 https://blog.csdn.net/weiwangchao_/article/details/50620301 没有必要过多的关心性能，因为二者的性能都已经足够高了。由于Redis只使用单核，而Memcached可以使用多核，所以在比较上，平均每一个核上Redis在存储小数据时比Memcached性能更高。而在100k以上的数据中，Memcached性能要高于Redis，虽然Redis最近也在存储大数据的性能上进行优化，但是比起Memcached，还是稍有逊色。说了这么多，结论是，无论你使用哪一个，每秒处理请求的次数都不会成为瓶颈。 如果要说内存使用效率，使用简单的key-value存储的话，Memcached的内存利用率更高，而如果Redis采用hash结构来做key-value存储，由于其组合式的压缩，其内存利用率会高于Memcached。当然，这和你的应用场景和数据特性有关。 如果你对数据持久化和数据同步有所要求，那么推荐你选择Redis，因为这两个特性Memcached都不具备。即使你只是希望在升级或者重启系统后缓存数据不会丢失，选择Redis也是明智的。 当然，最后还得说到你的具体应用需求。Redis相比Memcached来说，拥有更多的数据结构和并支持更丰富的数据操作，通常在Memcached里，你需要将数据拿到客户端来进行类似的修改再set回去。这大大增加了网络IO的次数和数据体积。在Redis中，这些复杂的操作通常和一般的GET/SET一样高效。所以，如果你需要缓存能够支持更复杂的结构和操作，那么Redis会是不错的选择。]]></content>
      <categories>
        <category>Redis</category>
      </categories>
      <tags>
        <tag>Redis</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[JVM-垃圾回收（1）-- 基础知识]]></title>
    <url>%2F2020%2F10%2F25%2FJVM-%E5%9E%83%E5%9C%BE%E5%9B%9E%E6%94%B6%EF%BC%881%EF%BC%89%2F</url>
    <content type="text"><![CDATA[前言 何为垃圾 如何发现垃圾？ 如何回收垃圾？ 堆内存逻辑分区 常见垃圾回收器 垃圾（Garbage）何为垃圾！？ 概念没有任何引用指向的单个或多个对象。 C/C++ 的处理C： malloc 申请内存 free 释放内存 C++： new 创建对象 delete 销毁对象 java 的处理 new 创建对象 自动回收对象 C/C++ vs javaC/C++： 手动处理垃圾，容易出错： 忘记回收 -&gt; 内存泄露 多次回收 -&gt; 非法访问 开发效率低，执行效率高 java： GC处理垃圾 开发效率高，执行效率低 垃圾定位方法引用计数（Reference Count） 每多一个引用指向某个对象，就将该对象的引用计数值+1，反之亦然。 无法解决循环引用（即几个对象相互引用，但实际并没有外部引用指向这其中的任何一个对象，因此这几个对象都是垃圾，但是他们的引用计数都不为0）的问题。 根可达算法（Root Searching） 从根对象（GC Roots）开始搜索，搜索所走过的路径称为引用链(Reference Chain)，当一个对象到 GC Roots 没有任何引用链相连时，则此对象垃圾。 哪些对象是根对象： 线程栈变量 JVM stacks JNI变量 native method stacks 常量池 runtime constant pool 静态变量 static reference in method area，Clazz 垃圾回收算法标记清除（Mark-Sweep） 如下图所示，将标记为垃圾的内存直接清理。 特点： 垃圾的内存位置不连续，容易产生碎片； 整个过程需要两遍扫描，效率偏低； 存活对象较多的情况下，效率相对较高。 拷贝（Copying） 如下图所示，将内存分为两块区域，每次只用其中一块区域，垃圾回收时，将存活的对象拷贝到另一半区域。 特点： 没有碎片； 浪费空间； 移动赋值对象，指针所指的对象地址需要调整； 只需要扫描一次，效率较高； 存活对象较少的情况下，效率相对较高。 标记压缩（Mark-Compact） 如下图所示，垃圾回收时，将存活的对象搬运到连续的内存中。 特点： 没有碎片； 整个过程需要两遍扫描，并且由于需要搬运对象，指针所指的对象地址需要调整，效率偏低。 内存逻辑分区背景可以看到不同的垃圾回收算法也有其各自的适用场景，因此，HotSpot在实现垃圾回收时，将堆内存划分成了两个区域：新生代（Young）和老年代（Old）。 顾名思义，新生代里存放的都是最近产生的对象，而老年代里，存放的是经过多次垃圾回收后，仍然存活的对象。因此，两者相较而言，垃圾回收时，通常新生代里存活的对象较少，而老年代里存活的对象较多。 根据不同区域中对象的特点不同，采用不同的垃圾回收器。 后面随着软硬件的发展，出现了不分代的垃圾回收器（如：G1 逻辑上分代，物理上不分代；ZGC，Shenandoah 逻辑和物理上都不分代） 因此，分代模型仅针对除了 Epsilon、ZGC 和 Shenandoah 以外的垃圾回收器。 分代模型 新生代（young） 老年代（old） 永久代（Perm Generation）/ 元数据区（Metaspace） 备注： 堆（Heap） 分为 新生代 和 老年代。 永久代 和 元数据区 都是 方法区（Method Area） 的具体实现，在jdk1.7及之前的版本中，叫 永久代，在jdk1.8及之后的版本中叫 元数据区。 Class对象在永久代/元数据区中。 永久代必须指定大小，运行过程中大小不会变，存满即报OOM，FGC不会清理Perm Generation；元数据区若不指定大小，则大小受限于物理内存，会触发FGC 字符串常量在jdk1.7及之前版本中，存放于 永久代，在jdk1.8及之后版本中，存放于 堆。 GC概念： MinorGC/YGC：对年轻代进行垃圾回收称为 MinorGC 或 YGC。年轻代空间耗尽时触发。 MajorGC/FullGC：对新生代和老年代都进行垃圾回收称为 MajorGC 或 FullGC。在老年代无法继续分配空间时触发。 新生代新生代（Young）又划分为 Eden 区 和 2个 survivor 区（s0 和 s1）。 Eden（伊甸）区 存放新生成的对象；两个Survivor（幸存）区 交替存放每次YGC后，存活下来的对象。 GC过程： YGC后，大多数对象被回收，存活的对象进入 s0 区 再次YGC，eden 区和 s0 区活着的对象进入 s1 区 再次YGC，eden 区和 s1 区活着的对象进入 s0 区 … 对象年龄足够，进入老年代。（CMS - 幸存6次后进入老年代；其他 - 幸存15次后进入老年代） 老年代老年代(Old)中存储的通常是顽固不易被回收的对象。老年代满了会触发FullGC。 对象分配过程 动态年龄分配担保常见垃圾回收器 如上图所示，除了 Epsilon 是用于调试以外，垃圾回收器大致可分为两类：使用分代模型的和不使用分代模型的。 几个基础概念STW： stop the world的缩写。 是指垃圾回收线程工作时，其他所有线程都暂停，等垃圾回收完毕，再恢复继续工作。 STW期间，业务线程也停了，因此业务会表现出没有响应的现象。 目前，所有的垃圾回收都有STW safe point： 基于分代模型的垃圾回收器使用分代模型的垃圾回收器，通常成对出现，分别用于Young区和Old区： Serial 和 Serial Old： 单线程回收 单CPU情况下，效率最高 适用于堆内存在 几十M左右 的情况 Serial使用拷贝算法，Serial Old使用标记清除压缩算法 Serial: a stop-the-world, copying collector which uses a single GC thread Serial Old: a stop-the-world, mark-sweep-compact collector that uses a single GC thread Parallel Scavenge 和 Parallel Old: 多线程回收 适用于堆内存在 上百M 到 几个G 之间的情况 是jdk1.8的默认垃圾回收器 Parallel Scavenge使用拷贝算法，Parallel Old使用标记压缩算法 Parallel Scavenge: a stop-the-world, copying collector which uses multiple GC threads Parallel Old：a stop-the world, compacting collector that uses multiple GC threads ParNew 和 CMS 适用于内存在 20 G 以下 的情况 ParaNew： ParNew 就是为了配合 CMS 使用，基于 Parallel Scavenge 的增强版本 a stop-the-world, copying collector which uses multiple GC threads. It differs from “Parallel Scavenge” in that it has enhancements that make it usable with CMS For Example, “ParNew” does the synchronization needed so that it can run during the concurrent phases of CMS CMS Concurrent Mark Sweep 的缩写 在JDK1.4版本后期引入，是里程碑式的GC，开启了 并发回收 的先河，但是由于 CMS 问题较多，目前没有任何一个版本的JDK使用 CMS 作为默认垃圾回收器。 并发回收： 随着物理内存越来越大，传统垃圾回收器GC产生的STW时间已经长到无法忍受。因此，为了缩短STW时间，产生了并发垃圾回收器。 并发垃圾回收器工作（即GC）的大部分时间内，其他线程也是正常运行的。只在某些必要阶段，会把其他线程暂停，因此，大大缩短了STW时间。 工作阶段： 初始标记（initial mark）：STW，标记根对象。 并发标记（concurrent mark）：标记非垃圾对象。使用 三色标记 算法。 重新标记（remark）：STW，修正并发标记阶段中，由于其他线程同时运行，而产生的错标和漏标。使用 Incremental Update 算法。 并发清理（concurrent sweep）：清理垃圾。使用 标记清除 算法。 CMS 的问题： 碎片化（Memory Fragmentation）：CMS默认使用标记清除算法，会产生内存碎片。 解决方法： -XX:UseCMSCompactAtFullCollection -XX:CMSFullGCBeforeCompaction=5 即进行了若干次（可配置，上例中是5）Full GC后，进行一次压缩算法。 浮动垃圾（Floating Garbage） CMS并发回收过程中，产生的垃圾，称为浮动垃圾，浮动垃圾需要等到下一次GC时才会回收。 但是浮动垃圾会产生下面2种情况： Concurrent Mode Failure：CMS和业务线程并发运行，在执行CMS的过程中有业务对象需要在老年代直接分配，例如大对象，但是老年代没有足够的空间来分配。 Promotion Failed：YGC后， Survivor空间容纳不了剩余对象，将要放入老年代，老年代有碎片或者不能容纳这些对象。 这两种情况，会进入STW，并降级使用Serial Old垃圾器进行FullGC，从而造成长时间的卡顿。 解决方法：+XX:CMSInitiatingOccupancyFraction=60 即适当调低老年代触发FullGC的阈值，以保证老年代有足够大的空间。 G1 Garbage First 的缩写 逻辑上分代，物理上不分代 适用于堆内存在 100 G 以下 的情况 并发标记阶段使用 三色标记 算法；重新标记阶段使用 SATB (snapshot at the beginning) 算法。 不使用分代模型的垃圾回收器ZGC 适用于堆内存在 16 T 以下 的情况 使用 颜色指针（Colored Pointers） + 读屏障（Load Barrier） Shenandoah 使用 颜色指针（Colored Pointers） + 写屏障（Load Barrier）]]></content>
      <categories>
        <category>JVM</category>
      </categories>
      <tags>
        <tag>JVM</tag>
        <tag>垃圾回收</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[JVM 运行时数据区及常用指令]]></title>
    <url>%2F2020%2F10%2F24%2FJVM-%E8%BF%90%E8%A1%8C%E6%97%B6%E6%95%B0%E6%8D%AE%E5%8C%BA%2F</url>
    <content type="text"><![CDATA[前言 JVM 运行时数据区的组成 栈帧 举例说明基于栈帧的运行机制 总结JVM中的常用指令 JVM 运行时数据区（Runtime Data areas）JVM 运行时数据区的组成 PC：Program Counter，程序计数器，保存了下一条指令的位置，每个线程都有一个PC Heap: 堆 JVM stacks: JVM的栈，每个线程都有一个栈，每个方法都有一个栈帧，栈帧存储在栈中 native method stacks：本地方法（如JNI）的栈，无法调优、管理，一般不用考虑 Direct Memory：jdk1.4以后，为提高效率，NIO使用直接内存访问内核空间的内存（零拷贝） method area： 方法区，存放了class数据、Run-time Constant Pool。 Permanent Generation 和 Meta Space 分别是 JDK1.8之前 和 JDK1.8及之后 对 method area 的实现 Perm Generation： &lt; JDK1.7 字符串常量存储在Perm Generation中 启动时可以指定Perm Generation大小，运行过程中大小不会变，存满即报OOM，FGC不会清理Perm Generation Meta Space >= JDK1.8 字符串常量位于堆 若不指定Meta Space大小，则大小受限于物理内存，会触发FGC 关于栈帧 目前实际的CPU大都是基于寄存器的指令集，而JVM是基于栈的指令集。 栈帧是JVM运行的一个重要机制。 每个方法都有一个栈帧，栈帧存储在栈中 一个栈帧内包含以下部分： 该方法的本地变量 Local Variables 该方法的操作数栈 Operand Stacks 动态链接 Dynamic Linking 返回地址 Retrun Address 接下来通过例子来说明JVM是如何运行的。 举例Talk is cheap. Show me the code! 一道无聊的面试题首先来看一道比较无聊的面试题：求下面这段代码的输出结果… 1234567public class Test1 &#123; public static void main(String[] args) &#123; int i = 8; i = i++; System.out.println(i); &#125;&#125; 答案是：8….还是9呢？ 我们看一下编译后的字节码就了然了。使用之前介绍的jclasslib工具，分析编译出的class文件，找到其中的main方法： 图中左半部分是main()方法编译后的字节码，右半部分是本地变量，可以看到其中0号变量是args，即main函数的输入参数，1号变量是i。 接下来，我们来一条条分析指令： bipush 8：将数字8放入操作数栈（即本方法的栈帧的Operand Stacks）中，现在栈中有一个数字8。 istore_1：从栈中取出一个int数，并赋值给1号本地变量。即将栈中的8弹出，并赋值给i。 此时，i=8，栈中为空。 iload_1：将1号本地变量入栈。此时，栈中又有了一个数字8。 iinc 1 by 1：将1号本地变量加1。在JVMS文档中可以看到这条指令是不影响操作数栈的，因此，此时，i变为9，栈中仍有一个数字8。 istore_1: 从栈中取出一个int数，并赋值给1号本地变量。即将栈中的8弹出，并赋值给i。 此时，i=8，栈中为空。 getstatic #2：解析常量池中2号常量的引用，即System.out iload_1：将1号本地变量入栈。此时，栈中又有了一个数字8。 invokevirtual #3：弹出栈中的数字8，并将其作为参数调用常量池中3号常量的方法引用，即println。于是打印出8。 return：返回。 虽然说看了字节码后，对于结果是了然了，但是，其实还是有一点小疑问的： 可以看到 i = i 这句话编译成字节码后就变成了两句: iload_1 和 istore_1，实际上就是先把i的值压栈，再弹出来赋回给i。 而 i++ 这句编译成字节码是 iinc 1 by 1，也就是把i的值加了1再赋值给i。 上面两个都没问题，可以问题是为啥 iinc 1 by 1要插在 iload_1 和 istore_1之间呢？如果是放在后面，那结果就是9了。 其实，如果把 i = i++; 改成 j = i++没有什么争议了，iinc 1 by 1 只要放在 iload_1 之后就可以，至于要不要放在istore_1后面，对结果其实没什么影响。可能编译器也没想到有人会写这么无聊的代码吧。 接下来，我们把 i = i++ 改为 i = ++i;再看看结果。 当然，结果是9。可以看到唯一的变化就是 iinc i by 1 和 iload_1 的顺序换了下。这从 i++ 和 ++i 的语义上也是能够理解的。 从这个例子，我们应该可以大致感受到JVM是如何运行的了，基本上各个指令都是对 栈帧 Frame 里的 操作数栈 Operand Stacks 和 本地变量 Local Variables 的操作。 上面的例子中只是运行了一个static函数，其中也没有任何方法调用，因此整个过程中，栈中只有一个栈帧，接下来我们再来看看方法调用的情况。 方法调用调用没有返回值的方法12345678910public class Test3_MethodWithoutReturn &#123; public static void main(String[] args) &#123; Test3_MethodWithoutReturn t = new Test3_MethodWithoutReturn(); t.m1(); &#125; public void m1() &#123; int i = 500; &#125;&#125; 下图左边是 main 方法编译后的字节码和本地变量表，右边是 m1 方法的字节码和本地变量表： 下面我们来过一遍执行流程： 首先执行main函数，线程栈中有1个main方法的栈帧： new #2：在JVMS文档中可以得知，new指令会从该类的常量池中找到2号常量所代表的类（本例中就是Test3_MethodWithoutReturn 类），会为该类的一个实例在堆中分配空间，对其成员变量赋默认值（ 注意：是默认值，不是初始值！默认值是每个类型各自的默认值，如int的默认值就是0，而初始值是指在构造方法中或成员变量声明处的赋值。赋初始值的操作是在构造函数执行时，才进行的）。并且生成的实例的引用会放入操作数栈中。此时main方法的栈中的操作数栈中有了一个Test3_MethodWithoutReturn实例的引用。 dup：将栈顶的元素复制一份入栈。此时，栈内有了两份同一个Test3_MethodWithoutReturn实例的引用。 invokespecial #3：将栈顶元素弹出作为参数，调用Test3_MethodWithoutReturn的构造方法。实际上栈顶元素就是 this，对于非静态方法来说，其本地变量的表第一个元素都是this，调用方法的时候也至少需要传入一个参数this（即实例的引用）。此时main方法的栈中的操作数栈只剩一个Test3_MethodWithoutReturn实例的引用。 astore_1：将栈顶元素弹出，赋值给1号本地变量，即t。此时t终于指向了初始化完成的Test3_MethodWithoutReturn实例，并且操作数栈又变为了空。 aload_1：将本地变量1入栈，此时栈中有1个元素：t。 invokevirtual #4：将栈顶元素t弹出作为参数，调用m1方法。正如之前所说，我们可以看到m1方法的本地变量表中，第一个元素就是this。 接下来就开始执行m1方法的字节码，线程栈中新压入了m1方法的栈帧： sipush 500：将500放入m1栈帧的操作数栈中。 istore_1：将栈顶元素弹出，并赋值给1号参数。即将i赋值为500 return：m1方法返回 m1的栈帧弹出，线程栈中又只有1个main方法的栈帧，回到之前调用m1方法处，继续向下执行： return： main方法返回。 调用有返回值的方法1234567891011public class Test4_MethodWithReturn &#123; public static void main(String[] args) &#123; Test4_MethodWithReturn t = new Test4_MethodWithReturn(); t.m1(); &#125; public int m1() &#123; int i = 500; return i; &#125;&#125; 和 Test3_MethodWithoutReturn 相比，只是在m1方法的最后加了一句 return i;。 下图左边是 main 方法编译后的字节码和本地变量表，右边是 m1 方法的字节码和本地变量表： 和 Test3_MethodWithoutReturn 对比，我们不难发现： m1方法的最后，先将i入栈，然后执行了 ireturn 指令。在JVMS文档中可知，和 return 相比，除了从当前方法返回，ireturn还会把本方法栈帧中的栈顶元素弹出，并压入到调用者栈帧的栈顶，也就是说，ireturn之后，i的值500，被放入到了main方法的栈帧的栈顶。 而main方法在调用完m1方法后，多了一个 pop 指令，也就是把m1方法返回时压入的500弹了出来。 调用有返回值的方法，并接收返回值1234567891011public class Test5_GetMethodReturn &#123; public static void main(String[] args) &#123; Test5_GetMethodReturn t = new Test5_GetMethodReturn(); int a = t.m1(); &#125; public int m1() &#123; int i = 500; return i; &#125;&#125; 和 Test4_MethodWithReturn 相比，在main方法中，声明了一个变量a来接收m1方法的返回值。 下图左边是 main 方法编译后的字节码和本地变量表，右边是 m1 方法的字节码和本地变量表： 和 Test4_MethodWithReturn 相比，不难发现： main方法的本地变量表中多了一个2号变量a main方法在调用完m1方法后，调用的 pop 指令变为了 istore_2 指令，即把返回的500从栈顶弹出，并赋值给2号本地变量a。 递归调用最后，我们再来看看递归调用在JVM中是如何运行的。 12345678910111213public class Test6_Recursion &#123; public static void main(String[] args) &#123; Test6_Recursion t = new Test6_Recursion(); int x = t.m(3); System.out.println(x); &#125; public int m(int n) &#123; if (n == 1) return 1; return n * m(n - 1); &#125;&#125; 下图左边是 main 方法编译后的字节码和本地变量表，右边是 m 方法的字节码和本地变量表： main方法没啥好说的，我们来看下m方法。 我们直接从main方法调用了t.m(3)处开始分析，对应的字节码是 invokevirtual #4，执行这条语句后，线程栈中压入m(3)的栈帧，PC指向m方法的字节码开始运行 执行前两条指令 iload_1 和 iconst_1，依次将1号本地变量n的值3和常量1压入m(3)栈帧的操作数栈中。 执行 if_icmpne 7 指令，将栈中的1和3弹出，比较两数，若相等，向下执行，若不等，跳转到代码段7，即跳过 iconst_1 和 ireturn， 从iload_1处开始执行。 向下依次执行 iload_1 mload_0 iload_1 iconst_1，依次向操作数栈中压入n的值3，this引用，n的值3和常量1 执行 isub 指令，将栈顶的两个元素3和1弹出相减，并将结果2压回栈中 执行 invokevirtual #4指令，将栈顶的2和this弹出作为参数调用m方法，即执行m(2)。此时m(3)栈帧的操作数栈中还剩余一个元素3。线程栈中压入m(2)的栈帧，PC指针又指向m方法字节码的开始位置。 执行m(2)的过程和执行m(3)类似，不再赘述，会继续执行m(1)。此时m(2)的栈帧的操作数栈中还剩余一个元素2。线程栈中压入m(1)的栈帧，PC指针又指向m方法字节码的开始位置。 执行m(1)的过程和m(2)、m(3)略有不同。 执行前两条指令 iload_1 和 iconst_1，依次将1号本地变量n的值1和常量1压入m(3)栈帧的操作数栈中。 执行 if_icmpne 7 指令，将栈中的1和1弹出，比较两数，相等，继续向下执行iconst_1，向m(1)栈帧的操作数栈中压入常量1。 执行 ireturn 指令，将本方法，即m(1)栈帧的操作数栈顶元素1弹出，并压入调用方，即m(2)栈帧的操作数栈中，接着返回m(2)的 imul指令处继续执行，m(1)的栈帧从线程栈中弹出。 至此，m(1)方法执行完成，返回到m(2)继续执行。 执行 imul 指令，m(2)栈帧的操作数栈顶的两个元素1和2被弹出，相乘后，将结果2压回栈顶。 执行 ireturn 指令，将m(2)栈帧的操作数栈顶的元素2弹出，并压入调用方，即m(3)栈帧的操作数栈顶，接着返回m(2)的 imul指令处继续执行，m(2)的栈帧从线程栈中弹出。 m(2)方法也执行完成，返回到m(3)继续执行，和m(2)的执行类似，栈顶两个元素2和3相乘，得到结果6，返回main方法。 最终在main方法中，结果6赋值给main方法的2号本地变量x。 JVM 常用指令在上面的举例分析中，常用的JVM指令我们基本都接触过了，下面简单汇总下，具体可以查阅JVMS文档。 变量读写 load：将本地变量的值压入操作数栈中，根据数据类型的不同，具体有aload，aaload，baload，caload，dload，faload，fload，iaload，iload，laload，lload，saload等 store：将操作数栈顶元素弹出，并赋值给本地变量，根据数据类型的不同，具体有astore，aastore，bastore，castore，dstore，fastore，fstore，iastore，istore，lastore，llstore，sastore等 栈操作 dup：复制栈顶元素 push：将一个元素压入栈中 pop：从栈顶弹出一个元素 iconst：将一个常量压入栈中 运算 add：加 sub：减 mul：乘 div：除 rem：取余 neg：取相反数 or：或 xor：异或 and：与 inc：自加操作，注意这条指令不影响操作数栈，直接对本地变量操作 比较跳转 if_acmp&lt;cond>：引用比较跳转 if_icmp&lt;cond>：int值比较跳转 if&lt;cond>：int值和0比较跳转 方法返回 return 方法调用 invokestatic：调用static方法 invokevirtual：调用某个对象的方法，自带多态 invokeinterface：调用接口对象的方法 invokespecial：调用可以直接定位、没有多态的方法（如private方法和构造方法） invokedynamic：lambda表达式、反射、其他动态语言（如scala kotlin）、CGLib或ASM动态产生的class，调用其中的方法]]></content>
      <categories>
        <category>JVM</category>
      </categories>
      <tags>
        <tag>JVM</tag>
        <tag>Runtime</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[class文件格式]]></title>
    <url>%2F2020%2F10%2F24%2Fclass%E6%96%87%E4%BB%B6%E6%A0%BC%E5%BC%8F%2F</url>
    <content type="text"><![CDATA[前言 class文件的格式 如何通过jclasslib插件解析class文件 class文件 java文件通过javac编译后得到class文件 是二进制字节流 比如一个最简单的java文件如下：12public class ClassFileFormatT01 &#123;&#125; 编译完成后得到 ClassFileFormatT01.class 文件 ，可以通过 notepad++ 中的 Hex-Editor 插件查看其16进制格式的内容： 123456789101112131415161718ca fe ba be 00 00 00 34 00 10 0a 00 03 00 0d 07 00 0e 07 00 0f 01 00 06 3c 69 6e 69 74 3e 01 00 03 28 29 56 01 00 04 43 6f 64 65 01 00 0f 4c 69 6e 65 4e 75 6d 62 65 72 54 61 62 6c 65 01 00 12 4c 6f 63 61 6c 56 61 72 69 61 62 6c 65 54 61 62 6c 65 01 00 04 74 68 69 73 01 00 14 4c 43 6c 61 73 73 46 69 6c 65 46 6f 72 6d 61 74 54 30 31 3b 01 00 0a 53 6f 75 72 63 65 46 69 6c 65 01 00 17 43 6c 61 73 73 46 69 6c 65 46 6f 72 6d 61 74 54 30 31 2e 6a 61 76 61 0c 00 04 00 05 01 00 12 43 6c 61 73 73 46 69 6c 65 46 6f 72 6d 61 74 54 30 31 01 00 10 6a 61 76 61 2f 6c 61 6e 67 2f 4f 62 6a 65 63 74 00 21 00 02 00 03 00 00 00 00 00 01 00 01 00 04 00 05 00 01 00 06 00 00 00 2f 00 01 00 01 00 00 00 05 2a b7 00 01 b1 00 00 00 02 00 07 00 00 00 06 00 01 00 00 00 01 00 08 00 00 00 0c 00 01 00 00 00 05 00 09 00 0a 00 00 00 01 00 0b 00 00 00 02 00 0c 接下来我们就来看看这些看似毫无头绪的二进制码代表着什么。 class文件格式class文件构成一个class文件由以下部分组成，如下图所示： class文件标志 Magic Number，4字节，固定为 0xcafe babe 版本号 Minor Version：2字节，jdk1.8编译出的class文件固定为0x0000 MajorVersion：2字节，jdk1.8编译出的class文件固定为0x0034 常量池信息 constant_pool_count：2字节，常量池内的常量的数量 constant_pool：常量池，由于其保留了index为0的常量，因此常量池里实际的常量池数量为constant_pool_count - 1 访问修饰符 access flags：2字节，用于描述该类是public还是private等等 当前类 this_class：2字节，当前类在常量池中的index，如：本例中等于2，则找到常量池中的2#常量，即可找到ClassFileFormatT01类的信息 父类 super_class：2字节，父类在常量池中的index，如：本例中等于3，则找到常量池中的3#常量，即可找到父类java/lang/Object的信息 接口信息 interfaces_count：2字节 interfaces：实际数量为 interfaces_count 属性信息 fields_count：2字节 fields：实际数量为 fields_count 方法信息 methods_count：2字节 methods：实际数量为 methods_count 附加属性信息 attributes_count：2字节 attributes：实际数量为 attributes_count 插件jclasslib上一节只是对class文件的构成做了一个概览性质的描述，实际上还有很多细节，比如：常量池中某一个常量的格式是怎样的？ 这些细节就放到文章最后以附录的形式贴上去吧，毕竟，一般也不太会人工一字节一字节的对着二进制码去解析。 我们可以通过 IDEA 中的 jclasslib 插件，方便的解析class文件。 安装完 jclasslib 插件后， 重启 IDEA，编译java文件，将光标放在该java文件中，就可以在 View 菜单下找到 Show Bytecode With jclasslib选项了。 我们通过 jclasslib 分析本文开头编译得到的 ClassFileFormatT01.class 文件，如下图所示： 可以看到在弹出的页面的左侧框中，有 General Information、Constant Pool、Interfaces、Fields、Methods、Attributes几个大类，右侧框内则是选中条目的详细信息。 比如点击概览信息 General Information，我们能看到该类的jdk编译版本为1.8，常量池数量为16，访问级别为public，类名是ClassFileFormatT01，父类是 java/lang/Object，接口数量和属性数量为0，方法数量为1，附加属性数量为1。 点开ConstanPool，还能看到常量池中每个常量的具体信息。 比如在总览信息中，This class 是 cp_info #2 &lt;ClassFileFormatT01&gt;，就表示2号常量中保存了 This class 的信息，于是我们找到2号常量，如下图所示，可以看到2号常量是一个类型为 CONSTANT_Class_info 的常量，它有一个 Class name 属性，即类名，这个属性的值又指向了14号常量。 我们再去看14号常量，可以看到14号常量是一个类型为 CONSTANT_Utf8_Info 的常量，即字符串，字符串的内容就是 ClassFileFormatT01，即类名。 此外，还有个值得注意的地方：源码中，我们什么都没写，但是编译出来的class文件中却有1个方法，并且方法的名称是 init，也就是说java帮我们自动生成了一个构造方法。 我们再来简单看下这个构造方法的字节码，就3个指令（点击指令，可以直接链接到Oracle官网文档该指令的描述处，非常方便）： 把0号本地变量压栈，0号变量可以在 init 下面的 Code 下面的 LocalVariableTable中找到，就是 this 调用了一个方法，这个方法要去1号常量里找，实际上就是父类即 java/lang/Object 的构造方法。 返回 附录：Class文件格式详情。。。实在是太多了。。。 详见《Java Virtual Machine Specification》的第四章 “4. The class File Format”]]></content>
      <categories>
        <category>JVM</category>
      </categories>
      <tags>
        <tag>JVM</tag>
        <tag>class文件</tag>
        <tag>jclasslib</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[JVM 基础知识]]></title>
    <url>%2F2020%2F10%2F21%2FJVM-%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86%2F</url>
    <content type="text"><![CDATA[前言JVM最基础的背景知识。 Java从编码到执行 java文件通过javac编译成class文件 程序运行时，类加载器将class加载进内存 代码由字节码解释器解释运行 或 由JIT即时编译器编译成本地代码运行 JVM 与 Java Java： 一种跨平台的语言，即不需要修改代码即可在Windows、Linux、MacOS等多个平台上运行 JVM： 一种跨语言的平台，任何语言，只要最后编译成符合规范的 .class 文件，即可在JVM上运行 是一种规范：Java Virtual Machine Specification 是虚构出来的一台计算机：有字节码指令集、内存管理（如 栈、堆、方法区等） 常见的 JVM 实现 HotSpot: 由Oracle官方发布、维护 可通过 java -version 查看 JRockit: BEA发布，曾号称世界上最快的JVM 被Oracle收购，已合并入HotSpot J9: IBM Microsoft VM Taobao VM: HotSpot 深度定制版本 Liquid VM: 直接针对硬件 azul zing: 商业收费版本，非常贵 最新垃圾回收的业界标杆 JDK、JRE、JVM的关系]]></content>
      <categories>
        <category>JVM</category>
      </categories>
      <tags>
        <tag>JVM</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[二叉树]]></title>
    <url>%2F2018%2F09%2F27%2Falgorithm-binaryTree%2F</url>
    <content type="text"><![CDATA[前言看，一棵二叉树！ 介绍定义二叉树是每个节点最多有两个子树的树结构。 形态如图2-1所示，二叉树有五种形态： 节点数为0，空集 仅有一个根节点 仅有左树 仅有右树 左右树均有 满二叉树与完全二叉树满二叉树如果二叉树中所有分支节点的度数都为2，并且叶子节点都在通一层次上，则二叉树为满二叉树。如图2-2所示： 完全二叉树对一棵具有n个节点的二叉树按层序排号，如果编号为i的节点与同样深度的满二叉树编号为i节点在二叉树中位置完全相同，就是完全二叉树。满二叉树必须是完全二叉树，反之则不一定成立。如图2-3所示： 完全二叉树有以下特点： 叶子节点只能出现在最下一层 最下层叶子节点一定集中在左部连续位置。 倒数第二层，如有叶子节点，一定出现在右部连续位置。 同样节点树的二叉树，完全二叉树的深度最小。 二叉树的性质 在二叉树的第i层上最多有 $ 2^{(i-1)} $ 个节点（i &gt;= 1）。 高度为k的二叉树，最多有 $ 2^k-1 $ 个节点 (k &gt;= 0)。 对任何一棵二叉树，如果其叶节点有n个，度为2的非叶子节点有m个，则n = m + 1。（该性质的证明见附录） 具有n个节点的完全二叉树的高度为 $ [log_2n] + 1 $ 存储结构由于二叉树每个节点最多只有两个子节点，因此通常每个节点中有两个指向子节点的指针，如图3-1所示：有时为了回溯父节点方便，还会在节点中增加一个指向父节点的指针。 java代码：12345678910111213141516171819202122232425262728293031class Node &#123; Integer val; Node left; Node right; Node parent; public Node() &#123; &#125; public Node(Integer val, Node left, Node right, Node parent) &#123; this.val = val; this.left = left; this.right = right; this.parent = parent; &#125; public Integer getVal() &#123; return val; &#125; public void setVal(Integer val) &#123; his.val = val; &#125; public Node getLeft() &#123; return left; &#125; public void setLeft(Node left) &#123; this.left = left; &#125; public Node getRight() &#123; return right; &#125; public void setRight(Node right) &#123; this.right = right; &#125; public Node getParent() &#123; return parent; &#125; public void setParent(Node parent) &#123; this.parent = parent; &#125;&#125; 操作对于一棵二叉树而言，主要有遍历、查找、插入、删除、查询树的高度、树的节点数量以及某个节点的层次等操作。 我们知道二叉树中的每个节点又包含了两棵子二叉树，这本身就是一种递归思想的体现，因此对二叉树的大部分操作使用递归的思想都可以很方便的实现。 广度优先遍历广度优先遍历实际就是按层次遍历，按节点层次从低到高的顺序遍历所有节点。 比如图2-3中的二叉树的广度优先遍历为：1 2 3 4 5 6 7 8 9 10 广度优先遍历似乎不太好用递归实现。 广度优先遍历需要使用队列：（1）首先向队列中插入二叉树的根节点（2）检查队列中是否有元素，如果队列中没有元素，遍历结束，如果有元素，进行下一步（3）将队列中的第一个节点弹出，遍历该节点（4）检查弹出的节点是否有左右子节点，若有，将其插入队列中（5）重复步骤（2） 该遍历方法运用了队列“先进先出”的特性，先插入的节点也先弹出被遍历。 123456789101112131415/** @brief 广度优先遍历 */public void breadthFisrtTraverse(Node node) &#123; LinkedList&lt;Node&gt; queue = new LinkedList&lt;Node&gt;(); queue.add(node); while (queue.size() &gt; 0) &#123; Node n = queue.removeFirst(); System.out.print(n.val + " "); if (n.left != null) queue.addLast(n.left); if (n.right != null) queue.addLast(n.right); &#125;&#125; 深度优先遍历深度优先遍历是沿着树的深度遍历树的节点，尽可能深的搜索树的分支。 深度优先遍历根据遍历时根节点的位置又分为前序、中序和后续遍历。 前序遍历前序遍历是指按照“根-&gt;左-&gt;右”的顺序，深度遍历二叉树。 比如图2-3中的二叉树的前序遍历为：1 2 4 8 9 5 10 3 6 7 1234567891011/** @brief 前序遍历 */public void preOrder(Node node) &#123; if (node == null) return; // 打印本节点内容 System.out.print(node.val + " "); // 打印左子树 preOrder(node.left); // 打印右子树 preOrder(node.right);&#125; 中序遍历中序遍历是指按照“左-&gt;根-&gt;右”的顺序，深度遍历二叉树。 比如图2-3中的二叉树的中序遍历为：8 4 9 2 10 5 1 6 3 7 1234567891011/** @brief 中序遍历 */public void midOrder(Node node) &#123; if (node == null) return; // 打印左子树 midOrder(node.left); // 打印本节点内容 System.out.print(node.val + " "); // 打印右子树 midOrder(node.right);&#125; 后序遍历前序遍历是指按照“左-&gt;右-&gt;根”的顺序，深度遍历二叉树。 比如图2-3中的二叉树的后序遍历为：8 9 4 10 5 2 6 7 3 1 1234567891011/** @brief 后序遍历 */public void postOrder(Node node) &#123; if (node == null) return; // 打印左子树 postOrder(node.left); // 打印右子树 postOrder(node.right); // 打印本节点内容 System.out.print(node.val + " ");&#125; 查找、插入和删除节点的查找、插入和删除其实都和树的节点顺序有关，比如常用的二叉排序树(BST)中，左节点&lt;根&lt;右节点。因此相关内容将在二叉排序树中再细讲。 查询树的高度123456/** @brief 查询以该节点为根的树的高度 */public Integer height(Node node) &#123; if (node == null) return 0; return 1 + Math.max(height(node.left), height(node.right));&#125; 查询树的节点数量123456/** @brief 查询以该节点为根的树的节点数量 */public Integer nodesNum(Node node) &#123; if (node == null) return 0; return 1 + nodesNum(node.right) + nodesNum(node.left);&#125; 查询节点的层次123456/** @brief 查询节点的层级 */public Integer level(Node node) &#123; if (node == root) return 1; return level(node.parent) + 1;&#125; 附录性质3的证明试证明: 对任何一棵二叉树，如果其叶节点有n个，度为2的非叶子节点有m个，则n = m + 1。证： 设一棵二叉树度为0的节点个数为 $ n_0 $, 度为1的节点个数为 $ n_1 $, 度为2的节点个数为 $ n_2 $, 二叉树的节点总数为 k 。则：$ k=0 \times n_0+1 \times n_1+2 \times n_2 + 1 $ —— (式 1)$ k=n_0+n_1+n_2 $ —— (式 2)两式相减可得：$ n_0=n_2+1 $ —— (式 3) 由题可知：叶子节点即度为0的节点，即：$ n_0 = n $;度为2的非叶子节点即度为2的节点，即：$ n_2 = m $; 代入式3可得：$ n=m+1 $]]></content>
      <categories>
        <category>数据结构</category>
      </categories>
      <tags>
        <tag>树</tag>
        <tag>数据结构</tag>
        <tag>二叉树</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[树]]></title>
    <url>%2F2018%2F09%2F10%2Falgorithm-Tree%2F</url>
    <content type="text"><![CDATA[前言今天说说树。下面这就是一棵树： 当然我们今天要说的是一种数据结构 - 树。 介绍树是8种基础数据结构（数组Array、栈Stack、队列Queue、链表LinkedList、树Tree、图Graph、堆Heap、散列表HashTable）之一。 一棵树通常可以表示为图2-1的形式，由于其形似一棵倒置的树，它也因此而得名。 定义树(Tree)是包含n(n &gt;= 0)个节点的有穷集合。当 n=0 时，称为 空树。对于任一棵 非空树（n &gt; 0），其满足以下特性： 树中的每个元素称之为 节点（node） 有一个特殊的节点称之为 根节点（root），根节点没有父节点 除根节点之外的其余数据元素被分为m（m&gt;=0）个互不相交的集合T1，T2，……，Tm-1，其中每一个集合Ti(1&lt;=i&lt;=m)本身也是一棵树，被称作原树的 子树（subtree） 根据上述定义，可以判断图2-2中的均不是树 我们也可以推导出树的一些性质: 子树是不相交的 除了根节点没有父节点，其余每个节点有且只有一个父节点 一棵有n个节点的树，有n-1条边 意义在笔者看来，树这种数据结构之所以存在有两方面原因： 自然界中本来就存在着许多以树状结构存在的事物（比如公司或部门的组织架构，家族图谱等），而程序是对自然界事物的抽象，那么树这种数据结构的出现就非常自然了； 在一些大数据量的场景下，树这种数据结构的搜索、插入、删除的综合性能相较与数组、链表有优势。 相关术语 节点的度（Degree）：一个节点含有的子树的个数称为该节点的度； 叶子节点（Leaf）：度为0的节点称为叶节点； 非终端节点或分支节点：度不为0的节点； 父节点（Parent）：若一个节点含有子节点，则这个节点称为其子节点的父节点； 子节点（Child）：一个节点含有的子树的根节点称为该节点的子节点； 兄弟节点（Sibling）：具有相同父节点的节点互称为兄弟节点； 树的度：一棵树中，最大的节点的度称为树的度； 节点的层次（Level）：从根开始定义起，根为第1层，根的子节点为第2层，以此类推； 树的高度或深度（Depth）：树中节点的最大层次； 祖先（Ancestor）：从根到该节点所经分支上的所有节点都称为该节点的祖先； 子孙（Descendant）：以某节点为根的子树中任一节点都称为该节点的子孙。 存储模型由于树的子节点的数量是不确定的，因此通常在节点内部使用链表在存储该节点的子节点，这种表示方法也被称为孩子兄弟表示法，即： 每个节点都有一个指向其第一个孩子的指针； 每个节点都有一个指向其第一个右兄弟的指针。 图2-1中的树的存储结构可以表示为图3-1所示： 分类及应用根据是否有序分类 无序树树的任意节点的子节点没有顺序关系。 有序树树的任意节点的子节点有顺序关系。 二叉树二叉树是应用非常广泛的一种树。二叉树是指：树的任意节点至多包含两棵子树。 满二叉树叶子节点都在同一层并且除叶子节点外的所有节点都有两个子节点。 完全二叉树对于一颗二叉树，假设其深度为d（d&gt;1）。除第d层外的所有节点构成满二叉树，且第d层所有节点从左向右连续地紧密排列，这样的二叉树被称为完全二叉树。 平衡二叉树它是一 棵空树或它的左右两个子树的高度差的绝对值不超过1，并且左右两个子树都是一棵平衡二叉树，同时，平衡二叉树必定是二叉搜索树。 常用的树 二叉查找树（又称二叉搜索树、二叉排序树、BST）若任意节点的左子树不空，则左子树上所有节点的值均小于它的根节点的值；若任意节点的右子树不空，则右子树上所有节点的值均大于它的根节点的值；任意节点的左、右子树也分别为二叉查找树；没有键值相等的节点。 红黑树红黑树是一颗特殊的二叉查找树，它有自平衡的特性，主要用于解决二叉查找树在某些情况下退化为链表而导致性能下降的问题。 字典树又称单词查找树，Trie树，是一种哈希树的变种。典型应用是用于统计，排序和保存大量的字符串（但不仅限于字符串），所以经常被搜索引擎系统用于文本词频统计。 后缀树后缀树（Suffix tree）就是包含一则字符串所有后缀的压缩Trie树。 霍夫曼树带权路径最短的二叉树称为哈夫曼树或最优二叉树。 2-3树、B树、B+树、B*树均为平衡查找树。]]></content>
      <categories>
        <category>数据结构</category>
      </categories>
      <tags>
        <tag>树</tag>
        <tag>数据结构</tag>
      </tags>
  </entry>
</search>
